{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EeXxUnFUvxTI",
    "outputId": "cfbe3155-24aa-4847-88fc-025de00f9228"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "F35rXN1ZBS_0",
    "outputId": "36b1b371-e727-4464-a9d9-f0fd77b1db62"
   },
   "outputs": [],
   "source": [
    "cd drive/My\\ Drive/Colab/YOLO-V3-Keras-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGj2PR7Svzlg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import colorsys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from   keras.models               import Sequential, Model ,model_from_yaml ,load_model\n",
    "from   keras.activations          import linear\n",
    "from   keras.layers.normalization import BatchNormalization\n",
    "from   keras.optimizers           import Adagrad\n",
    "from   keras.utils                import plot_model\n",
    "from   keras.engine.topology      import Layer\n",
    "from   yolo3.model                import yolo_eval\n",
    "from   keras                      import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRbDWEY0vxTR"
   },
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "weights_path   = '../../yolov3_weights.h5'\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "classes_path = 'model_data/coco_classes.txt'\n",
    "score = 0.3\n",
    "iou = 0.5\n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "849FnOrWvxTV"
   },
   "outputs": [],
   "source": [
    "def _get_class():\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbW2Q_ZsvxTZ"
   },
   "outputs": [],
   "source": [
    "def _get_anchors():\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        anchors = np.array(anchors).reshape(-1, 2)\n",
    "    return anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2LCF32KnvxTc"
   },
   "outputs": [],
   "source": [
    "def generate():\n",
    "    assert weights_path.endswith('.h5'), 'Keras model must be a .h5 file.'\n",
    "    print('{} model, anchors, and classes loaded.'.format(weights_path))\n",
    "    yaml_file = open('infer_model.yaml', 'r')\n",
    "    loaded_model_yaml = yaml_file.read()\n",
    "    yaml_file.close()\n",
    "    Infer_model = model_from_yaml(loaded_model_yaml)\n",
    "    Infer_model.load_weights(weights_path)\n",
    "    # Generate output tensor targets for filtered bounding boxes.\n",
    "    input_image_shape = K.placeholder(shape=(2, ))\n",
    "    boxes, scores, classes = yolo_eval(Infer_model.output, anchors,\n",
    "                                       len(class_names), input_image_shape,\n",
    "                                       score_threshold=score, iou_threshold=iou)\n",
    "    return Infer_model,boxes, scores, classes,input_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EeClfmIuvxTg"
   },
   "outputs": [],
   "source": [
    "def close_session(self):\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "biXOw5D8vxTl"
   },
   "outputs": [],
   "source": [
    "def detect_image(image,Infer_model,input_image_shape, database=None):\n",
    "    boxed_image = cv2.resize(image,model_image_size)\n",
    "    image_data  = np.array(boxed_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    out_boxes, out_scores, out_classes = sess.run(\n",
    "        [boxes, scores, classes],\n",
    "        feed_dict={\n",
    "            Infer_model.input: image_data,\n",
    "            input_image_shape: [boxed_image.shape[0], boxed_image.shape[1]],\n",
    "            K.learning_phase(): 0\n",
    "        })\n",
    "    return out_boxes, out_scores, out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U8EPAZA-vxTo",
    "outputId": "d9c82529-6eb5-4561-855b-c30de58343b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../yolov3_weights.h5 model, anchors, and classes loaded.\n"
     ]
    }
   ],
   "source": [
    "class_names = _get_class()\n",
    "anchors = _get_anchors()\n",
    "sess = K.get_session()\n",
    "hsv_tuples = [(x / len(class_names), 1., 1.)\n",
    "              for x in range(len(class_names))]\n",
    "colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255),\n",
    "                             int(x[2] * 255)),colors))\n",
    "random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "# Shuffle colors to decorrelate adjacent classes.\n",
    "random.shuffle(colors)\n",
    "random.seed(None)  # Reset seed to default.\n",
    "model_image_size = (416, 416)  # fixed size or (None, None)\n",
    "Infer_model,boxes, scores, classes,input_image_shape = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XgH_g1P-vxTt"
   },
   "outputs": [],
   "source": [
    "cap    = cv2.VideoCapture('tt2.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "width  = cap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT) # float\n",
    "out    = cv2.VideoWriter('tt2.mp4',fourcc, 25.0, (int(width),int(height)))\n",
    "label_size =int((width + height) // 300)\n",
    "he=height/416\n",
    "wi=width /416\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        out_boxes, out_scores, out_classes=detect_image(frame,Infer_model,input_image_shape)\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = round(float(out_scores[i]),2)\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            top, left, bottom, right = box\n",
    "            top    = int(max(0, np.floor(he*top + 0.5).astype('int32')))\n",
    "            left   = int(max(0, np.floor(wi*left + 0.5).astype('int32')))\n",
    "            bottom = int(min(height, np.floor(he*bottom + 0.5).astype('int32')))\n",
    "            right  = int(min(width, np.floor(wi*right + 0.5).astype('int32')))\n",
    "            # print(label, (left, top), (right, bottom), pos, c, type(top))\n",
    "            if top - label_size >= 0:\n",
    "                text_origin = np.array([left, top - label_size])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "            cv2.rectangle(frame,(left,top),(right,bottom),colors[c],3)    \n",
    "            cv2.putText(frame,label,tuple(text_origin),font,0.5,colors[c])\n",
    "        out.write(frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "nuDkpulZZTbi",
    "outputId": "576b1528-da39-4847-e904-0363f28d2fda"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-e78d4f3ac099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackerMedianFlow_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracker_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GOTURN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackerGOTURN_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracker_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MOSSE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackerMOSSE_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'TrackerGOTURN_create'"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('tt2.avi')\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT) # float\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('Manip.mp4',fourcc, 20.0, (int(width),int(height)))\n",
    "label_size = int((width + height) // 300)\n",
    "he=height/416\n",
    "wi=width/416\n",
    "tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW',\n",
    "                 'GOTURN', 'MOSSE', 'CSRT']\n",
    "tracker_type = tracker_types[5]\n",
    "\n",
    "if int(minor_ver) < 3:\n",
    "    tracker = cv2.Tracker_create(tracker_type)\n",
    "else:\n",
    "    if tracker_type == 'BOOSTING':\n",
    "        tracker = cv2.TrackerBoosting_create()\n",
    "    if tracker_type == 'MIL':\n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "    if tracker_type == 'KCF':\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "    if tracker_type == 'TLD':\n",
    "        tracker = cv2.TrackerTLD_create()\n",
    "    if tracker_type == 'MEDIANFLOW':\n",
    "        tracker = cv2.TrackerMedianFlow_create()\n",
    "    if tracker_type == 'GOTURN':\n",
    "        tracker = cv2.TrackerGOTURN_create()\n",
    "    if tracker_type == 'MOSSE':\n",
    "        tracker = cv2.TrackerMOSSE_create()\n",
    "    if tracker_type == \"CSRT\":\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret & (not (tr_ret)):\n",
    "        out_boxes, out_scores, out_classes=detect_image(frame,Infer_model,input_image_shape)\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = class_names[c]\n",
    "            if predicted_class=='car': \n",
    "                box = out_boxes[i]\n",
    "                score = round(float(out_scores[i]),2)\n",
    "                label = '{} {:.2f}'.format(predicted_class, score)\n",
    "                top, left, bottom, right = box\n",
    "                top    = int(max(0, np.floor(he*top + 0.5).astype('int32')))\n",
    "                left   = int(max(0, np.floor(wi*left + 0.5).astype('int32')))\n",
    "                bottom = int(min(height, np.floor(he*bottom + 0.5).astype('int32')))\n",
    "                right  = int(min(width, np.floor(wi*right + 0.5).astype('int32')))\n",
    "                if top - label_size >= 0:\n",
    "                    text_origin = np.array([left, top - label_size])\n",
    "                else:\n",
    "                    text_origin = np.array([left, top + 1])\n",
    "                cv2.rectangle(frame,(left,top),(right,bottom),colors[c],3)\n",
    "                cv2.putText(frame,label,tuple(text_origin),font,0.5,colors[c])\n",
    "                bbox=(left,top,right-left,bottom-top)\n",
    "                tr_ret=tracker.init(frame, bbox)\n",
    "            else:\n",
    "                continue\n",
    "        out.write(frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        if tr_ret:\n",
    "            tr_ret,bbox = tracker.update(frame)\n",
    "            if tr_ret:\n",
    "                p1 = (int(bbox[0]), int(bbox[1]))\n",
    "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "                cv2.rectangle(frame, p1, p2, colors[c],3)\n",
    "            else :\n",
    "                cv2.putText(frame, \"Tracking failure detected\", (100,80), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)            \n",
    "\n",
    "            out.write(frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZHKoQ_jEw9W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Inference Notebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
