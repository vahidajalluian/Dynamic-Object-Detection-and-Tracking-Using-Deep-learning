{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model V0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net Data\n",
    "    \n",
    "| batch=1 | subdivisions=1 | Training |\n",
    "| :---: | :---: | :---: |\n",
    "| decay=0.0005 | angle=0 | saturation = 1.5 |\n",
    "| batch=64 | subdivisions=16 | width=608 |\n",
    "| height=608 | channels=3 | momentum=0.9 |\n",
    "|exposure = 1.5 | hue=.1 | learning_rate=0.001|\n",
    "|burn_in=1000| max_batches = 500200| policy=steps|  \n",
    "|steps=400000,450000|scales=.1,.1||\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, Dense, Conv2D, LeakyReLU, ZeroPadding2D , Add , UpSampling2D , concatenate\n",
    "from keras.layers import concatenate\n",
    "from keras.activations import linear\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.utils import plot_model\n",
    "from keras.engine.topology import Layer\n",
    "from Yolo_layer import YoloLayer\n",
    "from Yolo_weight_catch import Yolo_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['person'       , 'bicycle'      , 'car'          , 'motorcycle',\n",
    "          'airplane'     , 'bus'          , 'train'        , 'truck', \n",
    "          'boat'         , 'traffic light', 'fire hydrant' ,'stop sign',\n",
    "          'parking meter', 'bench'        , 'bird'         , 'cat', \n",
    "          'dog'          , 'horse'        , 'sheep'        ,'cow' , \n",
    "          'elephant'     , 'bear'         , 'zebra'        ,'giraffe',\n",
    "          'backpack'     , 'umbrella'     , 'handbag'      ,'tie',\n",
    "          'suitcase'     , 'frisbee'      , 'skis'         ,'snowboard',\n",
    "          'sports ball'  , 'kite'         , 'baseball bat' , 'baseball glove',\n",
    "          'skateboard'   , 'surfboard'    , 'tennis racket','bottle',\n",
    "          'wine glass'   , 'cup'          , 'fork'         ,'knife',\n",
    "          'spoon'        , 'bowl'         , 'banana'       ,'apple',\n",
    "          'sandwich'     , 'orange'       , 'broccoli'     ,'carrot',\n",
    "          'hot dog'      , 'pizza'        , 'donut'        ,'cake',\n",
    "          'chair'        , 'couch'        , 'potted plant' ,'bed',\n",
    "          'dining table' , 'toilet'       , 'tv'           ,'laptop', \n",
    "          'mouse'        , 'remote'       , 'keyboard'     ,'cell phone',\n",
    "          'microwave'    , 'oven'         , 'toaster'      ,'sink', \n",
    "          'refrigerator' , 'book'         , 'clock'        , 'vase',\n",
    "          'scissors'     , 'teddy bear'   , 'hair drier'   , 'toothbrush']\n",
    "\n",
    "IMAGE_H = None\n",
    "IMAGE_W = None\n",
    "grid_scales = [7,17,37]\n",
    "nb_class         = len(labels)\n",
    "\n",
    "anchors          = [10,13,16,30,33,23,30,61,62,45,59,119,116,90,156,198,373,326]\n",
    "\n",
    "noobj_scale      = 1.0\n",
    "obj_scale        = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "class_scale      = 1.0\n",
    "\n",
    "batch_size       = 16\n",
    "warmup_batches   = 0\n",
    "TRUE_BOX_BUFFER  = 50\n",
    "\n",
    "Epsilon          = 0.001\n",
    "\n",
    "ALPHA = 0.1\n",
    "max_grid = [480,480]\n",
    "max_box_per_image = 20\n",
    "\n",
    "# num=9\n",
    "jitter=.3\n",
    "\n",
    "truth_thresh = 1\n",
    "random=1\n",
    "\n",
    "xywh_scale = 1\n",
    "ignore_thresh = .7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_h, net_w, 3\n",
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3),name='Main_Input') \n",
    "true_boxes  = Input(shape=(1, 1, 1, max_box_per_image, 4))\n",
    "# grid_h, grid_w, nb_anchor, pc+bx+by+bh+bw+nb_class\n",
    "true_yolo_1 = Input(shape=(None, None, len(anchors)//6, 5+nb_class)) \n",
    "true_yolo_2 = Input(shape=(None, None, len(anchors)//6, 5+nb_class)) \n",
    "true_yolo_3 = Input(shape=(None, None, len(anchors)//6, 5+nb_class)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv\n",
    "# Layer 1\n",
    "\n",
    "lay1_1 = Conv2D(32, (3,3), strides=(1, 1),use_bias=False, padding='same',name='Layer_1_CONV')(input_image)\n",
    "lay1_2 = BatchNormalization(epsilon=Epsilon,name='Layer_1_Batch')(lay1_1)\n",
    "lay1_3 = LeakyReLU(alpha=ALPHA,name='Layer_1_LRELU')(lay1_2)\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# Conv\n",
    "# Layer 2\n",
    "\n",
    "lay2_1 = ZeroPadding2D(((1,0),(1,0)),name='Layer_2_Zero_Padding')(lay1_3)\n",
    "lay2_2 = Conv2D(64, (3,3), strides=(2, 2),use_bias=False, padding='valid',name='Layer_2_CONV')(lay2_1)\n",
    "lay2_3 = BatchNormalization(epsilon=Epsilon,name='Layer_2_Batch')(lay2_2)\n",
    "lay2_4 = LeakyReLU(alpha=ALPHA,name='Layer_2_LRELU')(lay2_3)\n",
    "\n",
    "# Conv\n",
    "# Layer 3\n",
    "\n",
    "lay3_1 = Conv2D(32, (1,1), strides=(1, 1),use_bias=False, padding='same',name='Layer_3_CONV')(lay2_4)\n",
    "lay3_2 = BatchNormalization(epsilon=Epsilon,name='Layer_3_Batch')(lay3_1)\n",
    "lay3_3 = LeakyReLU(alpha=ALPHA,name='Layer_3_LRELU')(lay3_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 4\n",
    "\n",
    "lay4_1 = Conv2D(64, (3,3), strides=(1, 1),use_bias=False, padding='same',name='Layer_4_CONV')(lay3_3)\n",
    "lay4_2 = BatchNormalization(epsilon=Epsilon,name='Layer_4_Batch')(lay4_1)\n",
    "lay4_3 = LeakyReLU(alpha=ALPHA,name='Layer_4_LRELU')(lay4_2)\n",
    "\n",
    "# Shortcut\n",
    "# Layer 5\n",
    "\n",
    "lay5_1 = Add(name='Layer_5_Shortcut_Add')([lay2_4, lay4_3])\n",
    "lay5_2 = linear(lay5_1)\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# Conv\n",
    "# Layer 6\n",
    "\n",
    "lay6_1 = ZeroPadding2D(((1,0),(1,0)),name='Layer_6_Zero_Padding')(lay5_2)\n",
    "lay6_2 = Conv2D(128, (3,3), strides=(2, 2),use_bias=False, padding='valid',name='Layer_6_CONV')(lay6_1)\n",
    "lay6_3 = BatchNormalization(epsilon=Epsilon,name='Layer_6_Batch')(lay6_2)\n",
    "lay6_4 = LeakyReLU(alpha=ALPHA,name='Layer_6_LRELU')(lay6_3)\n",
    "\n",
    "# Conv\n",
    "# Layer 7\n",
    "\n",
    "lay7_1 = Conv2D(64, (1,1), strides=(1, 1), use_bias=False, padding='same',name='Layer_7_CONV')(lay6_4)\n",
    "lay7_2 = BatchNormalization(epsilon=Epsilon,name='Layer_7_Batch')(lay7_1)\n",
    "lay7_3 = LeakyReLU(alpha=ALPHA,name='Layer_7_LRELU')(lay7_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 8\n",
    "\n",
    "lay8_1 = Conv2D(128, (3,3), strides=(1, 1), use_bias=False, padding='same',name='Layer_8_CONV')(lay7_3)\n",
    "lay8_2 = BatchNormalization(epsilon=Epsilon,name='Layer_8_Batch')(lay8_1)\n",
    "lay8_3 = LeakyReLU(alpha=ALPHA,name='Layer_8_LRELU')(lay8_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 9\n",
    "\n",
    "lay9_1 = Add(name='Layer_9_Shortcut_Add')([lay6_4,lay8_3])\n",
    "lay9_2 = linear(lay9_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 10\n",
    "\n",
    "lay10_1 = Conv2D(64, (1,1), strides=(1, 1), use_bias=False, padding='same',name='Layer_10_CONV')(lay9_2)\n",
    "lay10_2 = BatchNormalization(epsilon=Epsilon,name='Layer_10_Batch')(lay10_1)\n",
    "lay10_3 = LeakyReLU(alpha=ALPHA,name='Layer_10_LRELU')(lay10_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 11\n",
    "\n",
    "lay11_1 = Conv2D(128, (3,3), strides=(1, 1), use_bias=False, padding='same',name='Layer_11_CONV')(lay10_3)\n",
    "lay11_2 = BatchNormalization(epsilon=Epsilon,name='Layer_11_Batch')(lay11_1)\n",
    "lay11_3 = LeakyReLU(alpha=ALPHA,name='Layer_11_LRELU')(lay11_2)\n",
    "\n",
    "# Shortcut \n",
    "# layer 12\n",
    "\n",
    "lay12_1 = Add(name='Layer_12_Shortcut_Add')([lay9_2,lay11_3])\n",
    "lay12_2 = linear(lay12_1)\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# Conv \n",
    "# Layer 13\n",
    "\n",
    "lay13_1 = ZeroPadding2D(((1,0),(1,0)),name='Layer_13_Zero_Padding')(lay12_2)\n",
    "lay13_2 = Conv2D(256, (3,3), strides=(2, 2), use_bias=False, padding='valid',name='Layer_13_CONV')(lay13_1)\n",
    "lay13_3 = BatchNormalization(epsilon=Epsilon,name='Layer_12_Batch')(lay13_2)\n",
    "lay13_4 = LeakyReLU(alpha=ALPHA,name='Layer_13_LRELU')(lay13_3)\n",
    "\n",
    "# Conv\n",
    "# Layer 14\n",
    "\n",
    "lay14_1 = Conv2D(128, (1,1), strides=(1, 1), use_bias=False, padding='same',name='Layer_14_CONV')(lay13_4)\n",
    "lay14_2 = BatchNormalization(epsilon=Epsilon,name='Layer_14_Batch')(lay14_1)\n",
    "lay14_3 = LeakyReLU(alpha=ALPHA,name='Layer_14_LRELU')(lay14_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 15\n",
    "\n",
    "lay15_1 = Conv2D(256, (3,3), strides=(1, 1), use_bias=False, padding='same',name='Layer_15_CONV')(lay14_3)\n",
    "lay15_2 = BatchNormalization(epsilon=Epsilon,name='Layer_15_Batch')(lay15_1)\n",
    "lay15_3 = LeakyReLU(alpha=ALPHA,name='Layer_15_LRELU')(lay15_2)\n",
    "\n",
    "\n",
    "# Shortcut\n",
    "# Layer 16\n",
    "\n",
    "lay16_1 = Add(name='Layer_16_Shortcut_Add')([lay13_4,lay15_3])\n",
    "lay16_2 = linear(lay16_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 17\n",
    "\n",
    "lay17_1 = Conv2D(128, (1,1), strides=(1, 1), use_bias=False, padding='same',name='Layer_17_CONV')(lay16_2)\n",
    "lay17_2 = BatchNormalization(epsilon=Epsilon,name='Layer_17_Batch')(lay17_1)\n",
    "lay17_3 = LeakyReLU(alpha=ALPHA,name='Layer_17_LRELU')(lay17_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 18\n",
    "\n",
    "lay18_1 = Conv2D(256, (3,3), strides=(1, 1), use_bias=False, padding='same',name='Layer_18_CONV')(lay17_3)\n",
    "lay18_2 = BatchNormalization(epsilon=Epsilon,name='Layer_18_Batch')(lay18_1)\n",
    "lay18_3 = LeakyReLU(alpha=ALPHA,name='Layer_18_LRELU')(lay18_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 19\n",
    "\n",
    "lay19_1 = Add(name='Layer_19_Shortcut_Add')([lay16_2,lay18_3])\n",
    "lay19_2 = linear(lay19_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 20\n",
    "\n",
    "lay20_1 = Conv2D(128, (1,1), strides=(1, 1), use_bias=False, padding='same',name='Layer_20_CONV')(lay19_2)\n",
    "lay20_2 = BatchNormalization(epsilon=Epsilon)(lay20_1)\n",
    "lay20_3 = LeakyReLU(alpha=ALPHA,name='Layer_20_LRELU')(lay20_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 21\n",
    "\n",
    "lay21_1 = Conv2D(256, (3,3), strides=(1, 1), use_bias=False, padding='same',name='Layer_21_CONV')(lay20_3)\n",
    "lay21_2 = BatchNormalization(epsilon=Epsilon)(lay21_1)\n",
    "lay21_3 = LeakyReLU(alpha=ALPHA,name='Layer_21_LRELU')(lay21_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 22\n",
    "\n",
    "lay22_1 = Add(name='Layer_22_Shortcut_Add')([lay19_2,lay21_3])\n",
    "lay22_2 = linear(lay22_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 23\n",
    "\n",
    "lay23_1 = Conv2D(128, (1,1), strides=(1, 1), use_bias=False, padding='same',name='Layer_23_CONV')(lay22_2)\n",
    "lay23_2 = BatchNormalization(epsilon=Epsilon)(lay23_1)\n",
    "lay23_3 = LeakyReLU(alpha=ALPHA,name='Layer_23_LRELU')(lay23_2)\n",
    "\n",
    "# Conv \n",
    "# Layer 24 \n",
    "\n",
    "lay24_1 = Conv2D(256, (3,3), strides=(1, 1), use_bias=False, padding='same',name='Layer_24_CONV')(lay23_3)\n",
    "lay24_2 = BatchNormalization(epsilon=Epsilon)(lay24_1)\n",
    "lay24_3 = LeakyReLU(alpha=ALPHA,name='Layer_24_LRELU')(lay24_2)\n",
    "\n",
    "\n",
    "# Shortcut \n",
    "# Layer 25\n",
    "\n",
    "lay25_1 = Add(name='Layer_25_Shortcut_Add')([lay22_2,lay24_3])\n",
    "lay25_2 = linear(lay25_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 26\n",
    "\n",
    "lay26_1 = Conv2D(128, (1,1), strides=(1, 1), use_bias=False, padding='same',name='Layer_26_CONV')(lay25_2)\n",
    "lay26_2 = BatchNormalization(epsilon=Epsilon)(lay26_1)\n",
    "lay26_3 = LeakyReLU(alpha=ALPHA,name='Layer_26_LRELU')(lay26_2)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 27\n",
    "\n",
    "lay27_1 = Conv2D(256, (3,3), strides=(1, 1), use_bias=False, padding='same',name='Layer_27_CONV')(lay26_3)\n",
    "lay27_2 = BatchNormalization(epsilon=Epsilon)(lay27_1)\n",
    "lay27_3 = LeakyReLU(alpha=ALPHA,name='Layer_27_LRELU')(lay27_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 28\n",
    "\n",
    "lay28_1 = Add(name='Layer_28_Shortcut_Add')([lay25_2,lay27_3])\n",
    "lay28_2 = linear(lay28_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 29\n",
    "\n",
    "lay29_1 = Conv2D(128, (1,1), strides=(1, 1), use_bias=False, padding='same',name='Layer_29_CONV')(lay28_2)\n",
    "lay29_2 = BatchNormalization(epsilon=Epsilon)(lay29_1)\n",
    "lay29_3 = LeakyReLU(alpha=ALPHA,name='Layer_29_LRELU')(lay29_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 30\n",
    "\n",
    "lay30_1 = Conv2D(256, (3,3), strides=(1, 1), use_bias=False, padding='same',name='Layer_30_CONV')(lay29_3)\n",
    "lay30_2 = BatchNormalization(epsilon=Epsilon)(lay30_1)\n",
    "lay30_3 = LeakyReLU(alpha=ALPHA,name='Layer_30_LRELU')(lay30_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 31\n",
    "\n",
    "lay31_1 = Add(name='Layer_31_Shortcut_Add')([lay28_2,lay30_3])\n",
    "lay31_2 = linear(lay31_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 32\n",
    "\n",
    "lay32_1 = Conv2D(128, (1,1), strides=(1, 1),use_bias=False, padding='same',name='Layer_32_CONV')(lay31_2)\n",
    "lay32_2 = BatchNormalization(epsilon=Epsilon)(lay32_1)\n",
    "lay32_3 = LeakyReLU(alpha=ALPHA,name='Layer_32_LRELU')(lay32_2)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 33\n",
    "\n",
    "lay33_1 = Conv2D(256, (3,3), strides=(1, 1),use_bias=False, padding='same',name='Layer_33_CONV')(lay32_3)\n",
    "lay33_2 = BatchNormalization(epsilon=Epsilon)(lay33_1)\n",
    "lay33_3 = LeakyReLU(alpha=ALPHA,name='Layer_33_LRELU')(lay33_2)\n",
    "\n",
    "# Shortcut\n",
    "# Layer 34\n",
    "\n",
    "lay34_1 = Add(name='Layer_34_Shortcut_Add')([lay31_2,lay33_3])\n",
    "lay34_2 = linear(lay34_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 35\n",
    "\n",
    "lay35_1 = Conv2D(128, (1,1), strides=(1, 1),use_bias=False, padding='same',name='Layer_35_CONV')(lay34_2)\n",
    "lay35_2 = BatchNormalization(epsilon=Epsilon)(lay35_1)\n",
    "lay35_3 = LeakyReLU(alpha=ALPHA,name='Layer_35_LRELU')(lay35_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 36\n",
    "\n",
    "lay36_1 = Conv2D(256, (3,3), strides=(1, 1),use_bias=False, padding='same',name='Layer_36_CONV')(lay35_3)\n",
    "lay36_2 = BatchNormalization(epsilon=Epsilon)(lay36_1)\n",
    "lay36_3 = LeakyReLU(alpha=ALPHA,name='Layer_36_LRELU')(lay36_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 37\n",
    "\n",
    "lay37_1 = Add(name='Layer_37_Shortcut_Add')([lay34_2,lay36_3])\n",
    "lay37_2 = linear(lay37_1)\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# Conv\n",
    "# Layer 38\n",
    "\n",
    "lay38_1 = ZeroPadding2D(((1,0),(1,0)),name='Layer_38_Zero_Padding')(lay37_2)\n",
    "lay38_2 = Conv2D(512, (3,3), strides=(2, 2),use_bias=False, padding='valid',name='Layer_38_CONV')(lay38_1)\n",
    "lay38_3 = BatchNormalization(epsilon=Epsilon)(lay38_2)\n",
    "lay38_4 = LeakyReLU(alpha=ALPHA,name='Layer_38_LRELU')(lay38_3)\n",
    "\n",
    "# Conv\n",
    "# Layer 39\n",
    "\n",
    "lay39_1 = Conv2D(256, (1,1), strides=(1, 1),use_bias=False, padding='same',name='Layer_39_CONV')(lay38_4)\n",
    "lay39_2 = BatchNormalization(epsilon=Epsilon)(lay39_1)\n",
    "lay39_3 = LeakyReLU(alpha=ALPHA)(lay39_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 40\n",
    "\n",
    "lay40_1 = Conv2D(512, (3,3), strides=(1, 1),use_bias=False, padding='same')(lay39_3)\n",
    "lay40_2 = BatchNormalization(epsilon=Epsilon)(lay40_1)\n",
    "lay40_3 = LeakyReLU(alpha=ALPHA)(lay40_2)\n",
    "\n",
    "\n",
    "# Shortcut\n",
    "# Layer 41\n",
    "\n",
    "lay41_1 = Add(name='Layer_41_Shortcut_Add')([lay40_3,lay38_4])\n",
    "lay41_2 = linear(lay41_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 42\n",
    "\n",
    "lay42_1 = Conv2D(256, (1,1), strides=(1, 1),use_bias=False, padding='same')(lay41_2)\n",
    "lay42_2 = BatchNormalization(epsilon=Epsilon)(lay42_1)\n",
    "lay42_3 = LeakyReLU(alpha=ALPHA)(lay42_2)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 43\n",
    "\n",
    "lay43_1 = Conv2D(512, (3,3), strides=(1, 1),use_bias=False, padding='same')(lay42_3)\n",
    "lay43_2 = BatchNormalization(epsilon=Epsilon)(lay43_1)\n",
    "lay43_3 = LeakyReLU(alpha=ALPHA)(lay43_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 44\n",
    "\n",
    "lay44_1 = Add()([lay43_3,lay41_2])\n",
    "lay44_2 = linear(lay44_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 45\n",
    "\n",
    "lay45_1 = Conv2D(256, (1,1), strides=(1, 1),use_bias=False, padding='same')(lay44_2)\n",
    "lay45_2 = BatchNormalization(epsilon=Epsilon)(lay45_1)\n",
    "lay45_3 = LeakyReLU(alpha=ALPHA)(lay45_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 46\n",
    "\n",
    "lay46_1 = Conv2D(512, (3,3), strides=(1, 1), use_bias=False, padding='same')(lay45_3)\n",
    "lay46_2 = BatchNormalization(epsilon=Epsilon)(lay46_1)\n",
    "lay46_3 = LeakyReLU(alpha=ALPHA)(lay46_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 47\n",
    "\n",
    "lay47_1 = Add()([lay46_3,lay44_2])\n",
    "lay47_2 = linear(lay47_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 48\n",
    "\n",
    "lay48_1 = Conv2D(256, (1,1), strides=(1, 1), use_bias=False, padding='same')(lay47_2)\n",
    "lay48_2 = BatchNormalization(epsilon=Epsilon)(lay48_1)\n",
    "lay48_3 = LeakyReLU(alpha=ALPHA)(lay48_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 49\n",
    "\n",
    "lay49_1 = Conv2D(512, (3,3), strides=(1, 1), use_bias=False, padding='same')(lay48_3)\n",
    "lay49_2 = BatchNormalization(epsilon=Epsilon)(lay49_1)\n",
    "lay49_3 = LeakyReLU(alpha=ALPHA)(lay49_2)\n",
    "\n",
    "# Shortcut\n",
    "# Layer 50\n",
    "\n",
    "lay50_1 = Add()([lay49_3,lay47_2])\n",
    "lay50_2 = linear(lay50_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 51\n",
    "\n",
    "lay51_1 = Conv2D(256, (1,1), strides=(1, 1), use_bias=False, padding='same')(lay50_2)\n",
    "lay51_2 = BatchNormalization(epsilon=Epsilon)(lay51_1)\n",
    "lay51_3 = LeakyReLU(alpha=ALPHA)(lay51_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 52\n",
    "\n",
    "lay52_1 = Conv2D(512, (3,3), strides=(1, 1), use_bias=False, padding='same')(lay51_3)\n",
    "lay52_2 = BatchNormalization(epsilon=Epsilon)(lay52_1)\n",
    "lay52_3 = LeakyReLU(alpha=ALPHA)(lay52_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 53\n",
    "\n",
    "lay53_1 = Add()([lay52_3,lay50_2])\n",
    "lay53_2 = linear(lay53_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 54\n",
    "\n",
    "lay54_1 = Conv2D(256,(1,1) , strides=(1, 1), use_bias=False, padding='same')(lay53_2)\n",
    "lay54_2 = BatchNormalization(epsilon=Epsilon)(lay54_1)\n",
    "lay54_3 = LeakyReLU(alpha=ALPHA)(lay54_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 55\n",
    "\n",
    "lay55_1 = Conv2D(512, (3,3), strides=(1, 1), use_bias=False, padding='same')(lay54_3)\n",
    "lay55_2 = BatchNormalization(epsilon=Epsilon)(lay55_1)\n",
    "lay55_3 = LeakyReLU(alpha=ALPHA)(lay55_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 56\n",
    "\n",
    "lay56_1 = Add()([lay55_3,lay53_2])\n",
    "lay56_2 = linear(lay56_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 57\n",
    "\n",
    "lay57_1 = Conv2D(256, 1, strides=(1, 1), use_bias=False, padding='same')(lay56_2)\n",
    "lay57_2 = BatchNormalization(epsilon=Epsilon)(lay57_1)\n",
    "lay57_3 = LeakyReLU(alpha=ALPHA)(lay57_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 58\n",
    "\n",
    "lay58_1 = Conv2D(512, 3, strides=(1, 1), use_bias=False, padding='same')(lay57_3)\n",
    "lay58_2 = BatchNormalization(epsilon=Epsilon)(lay58_1)\n",
    "lay58_3 = LeakyReLU(alpha=ALPHA)(lay58_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 59\n",
    "\n",
    "lay59_1 = Add()([lay58_3,lay56_2])\n",
    "lay59_2 = linear(lay59_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 60\n",
    "\n",
    "lay60_1 = Conv2D(256, 1, strides=(1, 1), use_bias=False, padding='same')(lay59_2)\n",
    "lay60_2 = BatchNormalization(epsilon=Epsilon)(lay60_1)\n",
    "lay60_3 = LeakyReLU(alpha=ALPHA)(lay60_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 61\n",
    "\n",
    "lay61_1 = Conv2D(512, 3, strides=(1, 1), use_bias=False, padding='same')(lay60_3)\n",
    "lay61_2 = BatchNormalization(epsilon=Epsilon)(lay61_1)\n",
    "lay61_3 = LeakyReLU(alpha=ALPHA)(lay61_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 62\n",
    "\n",
    "lay62_1 = Add()([lay61_3,lay59_2])\n",
    "lay62_2 = linear(lay62_1)\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# Conv\n",
    "# Layer 63\n",
    "\n",
    "lay63_1 = ZeroPadding2D(((1,0),(1,0)),name='Layer_63_Zero_Padding')(lay62_2)\n",
    "lay63_2 = Conv2D(1024, 3, strides=(2, 2), use_bias=False, padding='valid')(lay63_1)\n",
    "lay63_3 = BatchNormalization(epsilon=Epsilon)(lay63_2)\n",
    "lay63_4 = LeakyReLU(alpha=ALPHA)(lay63_3)\n",
    "\n",
    "# Conv\n",
    "# Layer 64\n",
    "\n",
    "lay64_1 = Conv2D(512, 1, strides=(1, 1), use_bias=False, padding='same')(lay63_4)\n",
    "lay64_2 = BatchNormalization(epsilon=Epsilon)(lay64_1)\n",
    "lay64_3 = LeakyReLU(alpha=ALPHA)(lay64_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 65\n",
    "\n",
    "lay65_1 = Conv2D(1024, 3, strides=(1, 1), use_bias=False, padding='same')(lay64_3)\n",
    "lay65_2 = BatchNormalization(epsilon=Epsilon)(lay65_1)\n",
    "lay65_3 = LeakyReLU(alpha=ALPHA)(lay65_2)\n",
    "\n",
    "# Shortcut\n",
    "# Layer 66\n",
    "\n",
    "lay66_1 = Add()([lay65_3,lay63_4])\n",
    "lay66_2 = linear(lay66_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 67\n",
    "\n",
    "lay67_1 = Conv2D(512, 1, strides=(1, 1), use_bias=False, padding='same')(lay66_2)\n",
    "lay67_2 = BatchNormalization(epsilon=Epsilon)(lay67_1)\n",
    "lay67_3 = LeakyReLU(alpha=ALPHA)(lay67_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 68\n",
    "\n",
    "lay68_1 = Conv2D(1024, (3,3), strides=(1, 1), use_bias=False, padding='same')(lay67_3)\n",
    "lay68_2 = BatchNormalization(epsilon=Epsilon)(lay68_1)\n",
    "lay68_3 = LeakyReLU(alpha=ALPHA)(lay68_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 69\n",
    "\n",
    "lay69_1 = Add()([lay68_3,lay66_2])\n",
    "lay69_2 = linear(lay69_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 70\n",
    "\n",
    "lay70_1 = Conv2D(512, (1,1), strides=(1, 1), use_bias=False, padding='same')(lay69_2)\n",
    "lay70_2 = BatchNormalization(epsilon=Epsilon)(lay70_1)\n",
    "lay70_3 = LeakyReLU(alpha=ALPHA)(lay70_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 71\n",
    "\n",
    "lay71_1 = Conv2D(1024, (3,3), strides=(1, 1), use_bias=False, padding='same')(lay70_3)\n",
    "lay71_2 = BatchNormalization(epsilon=Epsilon)(lay71_1)\n",
    "lay71_3 = LeakyReLU(alpha=ALPHA)(lay71_2)\n",
    "\n",
    "# Shortcut\n",
    "# Layer 72\n",
    "\n",
    "lay72_1 = Add()([lay71_3,lay69_2])\n",
    "lay72_2 = linear(lay72_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 73\n",
    "\n",
    "lay73_1 = Conv2D(512, (1,1), strides=(1, 1), use_bias=False, padding='same')(lay72_2)\n",
    "lay73_2 = BatchNormalization(epsilon=Epsilon)(lay73_1)\n",
    "lay73_3 = LeakyReLU(alpha=ALPHA)(lay73_2)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 74\n",
    "\n",
    "lay74_1 = Conv2D(1024, (3,3), strides=(1, 1), use_bias=False, padding='same')(lay73_3)\n",
    "lay74_2 = BatchNormalization(epsilon=Epsilon)(lay74_1)\n",
    "lay74_3 = LeakyReLU(alpha=ALPHA)(lay74_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 75\n",
    "\n",
    "lay75_1 = Add()([lay74_3,lay72_2])\n",
    "lay75_2 = linear(lay75_1)\n",
    "\n",
    "# ######################\n",
    "\n",
    "# Conv\n",
    "# Layer 76\n",
    "\n",
    "lay76_1 = Conv2D(512, 1, strides=(1, 1),use_bias=False, padding='same')(lay75_2)\n",
    "lay76_2 = BatchNormalization(epsilon=Epsilon)(lay76_1)\n",
    "lay76_3 = LeakyReLU(alpha=ALPHA)(lay76_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 77\n",
    "\n",
    "lay77_1 = Conv2D(1024, 3, strides=(1, 1),use_bias=False, padding='same')(lay76_3)\n",
    "lay77_2 = BatchNormalization(epsilon=Epsilon)(lay77_1)\n",
    "lay77_3 = LeakyReLU(alpha=ALPHA)(lay77_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 78\n",
    "\n",
    "lay78_1 = Conv2D(512, 1, strides=(1, 1),use_bias=False, padding='same')(lay77_3)\n",
    "lay78_2 = BatchNormalization(epsilon=Epsilon)(lay78_1)\n",
    "lay78_3 = LeakyReLU(alpha=ALPHA)(lay78_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 79\n",
    "\n",
    "lay79_1 = Conv2D(1024, 3, strides=(1, 1),use_bias=False, padding='same')(lay78_3)\n",
    "lay79_2 = BatchNormalization(epsilon=Epsilon)(lay79_1)\n",
    "lay79_3 = LeakyReLU(alpha=ALPHA)(lay79_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 80\n",
    "\n",
    "lay80_1 = Conv2D(512, 1, strides=(1, 1),use_bias=False, padding='same')(lay79_3)\n",
    "lay80_2 = BatchNormalization(epsilon=Epsilon)(lay80_1)\n",
    "lay80_3 = LeakyReLU(alpha=ALPHA)(lay80_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 81\n",
    "\n",
    "lay81_1 = Conv2D(1024, 3, strides=(1, 1),use_bias=False, padding='same')(lay80_3)\n",
    "lay81_2 = BatchNormalization(epsilon=Epsilon)(lay81_1)\n",
    "lay81_3 = LeakyReLU(alpha=ALPHA)(lay81_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 82\n",
    "\n",
    "lay82 = Conv2D(255, 1, strides=(1, 1),use_bias=True, padding='same')(lay81_3)\n",
    "\n",
    "# YOLO Detection Layer\n",
    "# Layer 83\n",
    "\n",
    "# Prediction Layer in First Scale\n",
    "# mask = 6,7,8\n",
    "\n",
    "# Loss Layer in First Scale\n",
    "loss_yolo_1 = YoloLayer(anchors[12:], \n",
    "                        [1*num for num in max_grid], \n",
    "                        batch_size, \n",
    "                        warmup_batches, \n",
    "                        ignore_thresh, \n",
    "                        grid_scales[0],\n",
    "                        obj_scale,\n",
    "                        noobj_scale,\n",
    "                        xywh_scale,\n",
    "                        class_scale)([input_image, lay82, \n",
    "                                      true_yolo_1, true_boxes])\n",
    "\n",
    "\n",
    "# Route (Skip)\n",
    "# Layer 84\n",
    "\n",
    "lay84=lay80_3\n",
    "\n",
    "# Conv\n",
    "# Layer 85\n",
    "\n",
    "lay85_1 = Conv2D(256, 1, strides=(1, 1),use_bias=False, padding='same')(lay84)\n",
    "lay85_2 = BatchNormalization(epsilon=Epsilon)(lay85_1)\n",
    "lay85_3 = LeakyReLU(alpha=ALPHA)(lay85_2)\n",
    "\n",
    "# [upsample] 86\n",
    "# stride=2\n",
    "\n",
    "lay86_1 = UpSampling2D(size=(2,2))(lay85_3)\n",
    "\n",
    "# [route] 87 Concatenante\n",
    "# layers = -1, 61\n",
    "\n",
    "lay87_1 = concatenate([lay86_1,lay62_2],axis=-1)\n",
    "\n",
    "# Conv\n",
    "# Layer 88\n",
    "\n",
    "lay88_1 = Conv2D(256, 1, strides=(1, 1),use_bias=False, padding='same')(lay87_1)\n",
    "lay88_2 = BatchNormalization(epsilon=Epsilon)(lay88_1)\n",
    "lay88_3 = LeakyReLU(alpha=ALPHA)(lay88_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 89\n",
    "\n",
    "lay89_1 = Conv2D(512, 3, strides=(1, 1),use_bias=False, padding='same')(lay88_3)\n",
    "lay89_2 = BatchNormalization(epsilon=Epsilon)(lay89_1)\n",
    "lay89_3 = LeakyReLU(alpha=ALPHA)(lay89_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 90\n",
    "\n",
    "lay90_1 = Conv2D(256, 1, strides=(1, 1),use_bias=False, padding='same')(lay89_3)\n",
    "lay90_2 = BatchNormalization(epsilon=Epsilon)(lay90_1)\n",
    "lay90_3 = LeakyReLU(alpha=ALPHA)(lay90_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 91\n",
    "\n",
    "lay91_1 = Conv2D(512, 3, strides=(1, 1),use_bias=False, padding='same')(lay90_3)\n",
    "lay91_2 = BatchNormalization(epsilon=Epsilon)(lay91_1)\n",
    "lay91_3 = LeakyReLU(alpha=ALPHA)(lay91_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 92\n",
    "\n",
    "lay92_1 = Conv2D(256, 1, strides=(1, 1),use_bias=False, padding='same')(lay91_3)\n",
    "lay92_2 = BatchNormalization(epsilon=Epsilon)(lay92_1)\n",
    "lay92_3 = LeakyReLU(alpha=ALPHA)(lay92_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 93\n",
    "\n",
    "lay93_1 = Conv2D(512, 3, strides=(1, 1),use_bias=False, padding='same')(lay92_3)\n",
    "lay93_2 = BatchNormalization(epsilon=Epsilon)(lay93_1)\n",
    "lay93_3 = LeakyReLU(alpha=ALPHA)(lay93_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 94\n",
    "\n",
    "lay94 = Conv2D(255, 1, strides=(1, 1),use_bias=True, padding='same')(lay93_3)\n",
    "\n",
    "# YOLO Detection Layer\n",
    "# Layer 95\n",
    "\n",
    "# Prediction Layer in First Scale\n",
    "# mask = 3,4,5\n",
    "\n",
    "loss_yolo_2 = YoloLayer(anchors[6:12], \n",
    "                        [1*num for num in max_grid], \n",
    "                        batch_size, \n",
    "                        warmup_batches, \n",
    "                        ignore_thresh, \n",
    "                        grid_scales[1],\n",
    "                        obj_scale,\n",
    "                        noobj_scale,\n",
    "                        xywh_scale,\n",
    "                        class_scale)([input_image, lay94, \n",
    "                                      true_yolo_2, true_boxes])\n",
    "# Route (Skip)\n",
    "# Layer 96\n",
    "\n",
    "lay96=lay92_3\n",
    "\n",
    "# Conv\n",
    "# Layer 97\n",
    "\n",
    "lay97_1 = Conv2D(128, 1, strides=(1, 1),use_bias=False, padding='same')(lay96)\n",
    "lay97_2 = BatchNormalization(epsilon=Epsilon)(lay97_1)\n",
    "lay97_3 = LeakyReLU(alpha=ALPHA)(lay97_2)\n",
    "\n",
    "# Upsample\n",
    "# Layer 98\n",
    "# stride=2\n",
    "\n",
    "lay98 = UpSampling2D(size=(2,2))(lay97_3)\n",
    "\n",
    "# [route] 99\n",
    "# layers = -1, 36\n",
    "\n",
    "lay99 = concatenate([lay98,lay37_2],axis=-1)\n",
    "\n",
    "# Conv \n",
    "# Layer 100\n",
    "\n",
    "lay100_1 = Conv2D(128, 1, strides=(1, 1),use_bias=False, padding='same')(lay99)\n",
    "lay100_2 = BatchNormalization(epsilon=Epsilon)(lay100_1)\n",
    "lay100_3 = LeakyReLU(alpha=ALPHA)(lay100_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 101\n",
    "\n",
    "lay101_1 = Conv2D(256, (3,3), strides=(1, 1),use_bias=False, padding='same')(lay100_3)\n",
    "lay101_2 = BatchNormalization(epsilon=Epsilon)(lay101_1)\n",
    "lay101_3 = LeakyReLU(alpha=ALPHA)(lay101_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 102\n",
    "\n",
    "lay102_1 = Conv2D(128, (1,1), strides=(1, 1), use_bias=False, padding='same')(lay101_3)\n",
    "lay102_2 = BatchNormalization(epsilon=Epsilon)(lay102_1)\n",
    "lay102_3 = LeakyReLU(alpha=ALPHA)(lay102_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 103\n",
    "\n",
    "lay103_1 = Conv2D(256, (3,3), strides=(1, 1), use_bias=False, padding='same')(lay102_3)\n",
    "lay103_2 = BatchNormalization(epsilon=Epsilon)(lay103_1)\n",
    "lay103_3 = LeakyReLU(alpha=ALPHA)(lay103_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 104\n",
    "\n",
    "lay104_1 = Conv2D(128, (1,1), strides=(1, 1), use_bias=False, padding='same')(lay103_3)\n",
    "lay104_2 = BatchNormalization(epsilon=Epsilon)(lay104_1)\n",
    "lay104_3 = LeakyReLU(alpha=ALPHA)(lay104_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 105\n",
    "\n",
    "lay105_1 = Conv2D(256, (3,3), strides=(1, 1),use_bias=False, padding='same')(lay104_3)\n",
    "lay105_2 = BatchNormalization(epsilon=Epsilon)(lay105_1)\n",
    "lay105_3 = LeakyReLU(alpha=ALPHA)(lay105_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 106\n",
    "\n",
    "lay106 = Conv2D(255, (1,1), strides=(1, 1), use_bias=True, padding='same')(lay105_3)\n",
    "\n",
    "# [yolo] \n",
    "# Layer 107\n",
    "# mask = 0,1,2\n",
    "loss_yolo_3 = YoloLayer(anchors[:6], \n",
    "                        [1*num for num in max_grid], \n",
    "                        batch_size, \n",
    "                        warmup_batches, \n",
    "                        ignore_thresh, \n",
    "                        grid_scales[2],\n",
    "                        obj_scale,\n",
    "                        noobj_scale,\n",
    "                        xywh_scale,\n",
    "                        class_scale)([input_image, lay106, \n",
    "                                      true_yolo_3, true_boxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = Model([input_image, true_boxes, true_yolo_1, true_yolo_2, true_yolo_3], [loss_yolo_1, loss_yolo_2, loss_yolo_3])\n",
    "infer_model = Model(input_image, [lay82, lay94, lay106])\n",
    "\n",
    "plot_model(train_model, to_file='train_model.png',show_shapes='true')\n",
    "plot_model(infer_model, to_file='infer_model.png',show_shapes='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Main_Input (InputLayer)         (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Layer_1_CONV (Conv2D)           (None, None, None, 3 864         Main_Input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Layer_1_Batch (BatchNormalizati (None, None, None, 3 128         Layer_1_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer_1_LRELU (LeakyReLU)       (None, None, None, 3 0           Layer_1_Batch[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_2_Zero_Padding (ZeroPaddi (None, None, None, 3 0           Layer_1_LRELU[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_2_CONV (Conv2D)           (None, None, None, 6 18432       Layer_2_Zero_Padding[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer_2_Batch (BatchNormalizati (None, None, None, 6 256         Layer_2_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer_2_LRELU (LeakyReLU)       (None, None, None, 6 0           Layer_2_Batch[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_3_CONV (Conv2D)           (None, None, None, 3 2048        Layer_2_LRELU[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_3_Batch (BatchNormalizati (None, None, None, 3 128         Layer_3_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer_3_LRELU (LeakyReLU)       (None, None, None, 3 0           Layer_3_Batch[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_4_CONV (Conv2D)           (None, None, None, 6 18432       Layer_3_LRELU[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_4_Batch (BatchNormalizati (None, None, None, 6 256         Layer_4_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer_4_LRELU (LeakyReLU)       (None, None, None, 6 0           Layer_4_Batch[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_5_Shortcut_Add (Add)      (None, None, None, 6 0           Layer_2_LRELU[0][0]              \n",
      "                                                                 Layer_4_LRELU[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_6_Zero_Padding (ZeroPaddi (None, None, None, 6 0           Layer_5_Shortcut_Add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer_6_CONV (Conv2D)           (None, None, None, 1 73728       Layer_6_Zero_Padding[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer_6_Batch (BatchNormalizati (None, None, None, 1 512         Layer_6_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer_6_LRELU (LeakyReLU)       (None, None, None, 1 0           Layer_6_Batch[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_7_CONV (Conv2D)           (None, None, None, 6 8192        Layer_6_LRELU[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_7_Batch (BatchNormalizati (None, None, None, 6 256         Layer_7_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer_7_LRELU (LeakyReLU)       (None, None, None, 6 0           Layer_7_Batch[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_8_CONV (Conv2D)           (None, None, None, 1 73728       Layer_7_LRELU[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_8_Batch (BatchNormalizati (None, None, None, 1 512         Layer_8_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer_8_LRELU (LeakyReLU)       (None, None, None, 1 0           Layer_8_Batch[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_9_Shortcut_Add (Add)      (None, None, None, 1 0           Layer_6_LRELU[0][0]              \n",
      "                                                                 Layer_8_LRELU[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_10_CONV (Conv2D)          (None, None, None, 6 8192        Layer_9_Shortcut_Add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer_10_Batch (BatchNormalizat (None, None, None, 6 256         Layer_10_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_10_LRELU (LeakyReLU)      (None, None, None, 6 0           Layer_10_Batch[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_11_CONV (Conv2D)          (None, None, None, 1 73728       Layer_10_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_11_Batch (BatchNormalizat (None, None, None, 1 512         Layer_11_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_11_LRELU (LeakyReLU)      (None, None, None, 1 0           Layer_11_Batch[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_12_Shortcut_Add (Add)     (None, None, None, 1 0           Layer_9_Shortcut_Add[0][0]       \n",
      "                                                                 Layer_11_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_13_Zero_Padding (ZeroPadd (None, None, None, 1 0           Layer_12_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_13_CONV (Conv2D)          (None, None, None, 2 294912      Layer_13_Zero_Padding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_12_Batch (BatchNormalizat (None, None, None, 2 1024        Layer_13_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_13_LRELU (LeakyReLU)      (None, None, None, 2 0           Layer_12_Batch[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_14_CONV (Conv2D)          (None, None, None, 1 32768       Layer_13_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_14_Batch (BatchNormalizat (None, None, None, 1 512         Layer_14_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_14_LRELU (LeakyReLU)      (None, None, None, 1 0           Layer_14_Batch[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_15_CONV (Conv2D)          (None, None, None, 2 294912      Layer_14_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_15_Batch (BatchNormalizat (None, None, None, 2 1024        Layer_15_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_15_LRELU (LeakyReLU)      (None, None, None, 2 0           Layer_15_Batch[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_16_Shortcut_Add (Add)     (None, None, None, 2 0           Layer_13_LRELU[0][0]             \n",
      "                                                                 Layer_15_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_17_CONV (Conv2D)          (None, None, None, 1 32768       Layer_16_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_17_Batch (BatchNormalizat (None, None, None, 1 512         Layer_17_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_17_LRELU (LeakyReLU)      (None, None, None, 1 0           Layer_17_Batch[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_18_CONV (Conv2D)          (None, None, None, 2 294912      Layer_17_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_18_Batch (BatchNormalizat (None, None, None, 2 1024        Layer_18_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_18_LRELU (LeakyReLU)      (None, None, None, 2 0           Layer_18_Batch[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_19_Shortcut_Add (Add)     (None, None, None, 2 0           Layer_16_Shortcut_Add[0][0]      \n",
      "                                                                 Layer_18_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_20_CONV (Conv2D)          (None, None, None, 1 32768       Layer_19_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 1 512         Layer_20_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_20_LRELU (LeakyReLU)      (None, None, None, 1 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_21_CONV (Conv2D)          (None, None, None, 2 294912      Layer_20_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 2 1024        Layer_21_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_21_LRELU (LeakyReLU)      (None, None, None, 2 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_22_Shortcut_Add (Add)     (None, None, None, 2 0           Layer_19_Shortcut_Add[0][0]      \n",
      "                                                                 Layer_21_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_23_CONV (Conv2D)          (None, None, None, 1 32768       Layer_22_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 1 512         Layer_23_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_23_LRELU (LeakyReLU)      (None, None, None, 1 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_24_CONV (Conv2D)          (None, None, None, 2 294912      Layer_23_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 2 1024        Layer_24_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_24_LRELU (LeakyReLU)      (None, None, None, 2 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_25_Shortcut_Add (Add)     (None, None, None, 2 0           Layer_22_Shortcut_Add[0][0]      \n",
      "                                                                 Layer_24_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_26_CONV (Conv2D)          (None, None, None, 1 32768       Layer_25_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 512         Layer_26_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_26_LRELU (LeakyReLU)      (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_27_CONV (Conv2D)          (None, None, None, 2 294912      Layer_26_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 2 1024        Layer_27_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_27_LRELU (LeakyReLU)      (None, None, None, 2 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_28_Shortcut_Add (Add)     (None, None, None, 2 0           Layer_25_Shortcut_Add[0][0]      \n",
      "                                                                 Layer_27_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_29_CONV (Conv2D)          (None, None, None, 1 32768       Layer_28_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 1 512         Layer_29_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_29_LRELU (LeakyReLU)      (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_30_CONV (Conv2D)          (None, None, None, 2 294912      Layer_29_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 2 1024        Layer_30_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_30_LRELU (LeakyReLU)      (None, None, None, 2 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_31_Shortcut_Add (Add)     (None, None, None, 2 0           Layer_28_Shortcut_Add[0][0]      \n",
      "                                                                 Layer_30_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_32_CONV (Conv2D)          (None, None, None, 1 32768       Layer_31_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 1 512         Layer_32_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_32_LRELU (LeakyReLU)      (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_33_CONV (Conv2D)          (None, None, None, 2 294912      Layer_32_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 2 1024        Layer_33_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_33_LRELU (LeakyReLU)      (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Layer_34_Shortcut_Add (Add)     (None, None, None, 2 0           Layer_31_Shortcut_Add[0][0]      \n",
      "                                                                 Layer_33_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_35_CONV (Conv2D)          (None, None, None, 1 32768       Layer_34_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 1 512         Layer_35_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_35_LRELU (LeakyReLU)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Layer_36_CONV (Conv2D)          (None, None, None, 2 294912      Layer_35_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 2 1024        Layer_36_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_36_LRELU (LeakyReLU)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Layer_37_Shortcut_Add (Add)     (None, None, None, 2 0           Layer_34_Shortcut_Add[0][0]      \n",
      "                                                                 Layer_36_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Layer_38_Zero_Padding (ZeroPadd (None, None, None, 2 0           Layer_37_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_38_CONV (Conv2D)          (None, None, None, 5 1179648     Layer_38_Zero_Padding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 5 2048        Layer_38_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_38_LRELU (LeakyReLU)      (None, None, None, 5 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Layer_39_CONV (Conv2D)          (None, None, None, 2 131072      Layer_38_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 2 1024        Layer_39_CONV[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 5 1179648     leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 5 2048        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 5 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Layer_41_Shortcut_Add (Add)     (None, None, None, 5 0           leaky_re_lu_2[0][0]              \n",
      "                                                                 Layer_38_LRELU[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 2 131072      Layer_41_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 2 1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 5 1179648     leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 5 2048        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 5 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 5 0           leaky_re_lu_4[0][0]              \n",
      "                                                                 Layer_41_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 2 131072      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 2 1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 5 1179648     leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 5 2048        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 5 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 5 0           leaky_re_lu_6[0][0]              \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 2 131072      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 2 1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 5 1179648     leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 5 2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 5 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 5 0           leaky_re_lu_8[0][0]              \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 2 131072      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 2 1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 5 1179648     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 5 2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 5 0           leaky_re_lu_10[0][0]             \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 2 131072      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 5 2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 5 0           leaky_re_lu_12[0][0]             \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 2 131072      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 5 2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 5 0           leaky_re_lu_14[0][0]             \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 2 131072      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 5 0           leaky_re_lu_16[0][0]             \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_63_Zero_Padding (ZeroPadd (None, None, None, 5 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 1 4718592     Layer_63_Zero_Padding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 1 4096        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 5 2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 4096        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 1 0           leaky_re_lu_19[0][0]             \n",
      "                                                                 leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 5 524288      add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 5 2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 4096        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 1 0           leaky_re_lu_21[0][0]             \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 5 524288      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 5 2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 4096        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 1 0           leaky_re_lu_23[0][0]             \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 5 524288      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 5 2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 4096        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           leaky_re_lu_25[0][0]             \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 5 524288      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 5 2048        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 4096        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 5 2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 4096        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 5 2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 2 1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 2 196608      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 2 1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 5 2048        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 2 1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 5 2048        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 2 1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_2[0][0]            \n",
      "                                                                 Layer_37_Shortcut_Add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 49152       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 512         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 2 1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 512         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 2 1024        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 512         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 4096        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 5 2048        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 2 1024        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 2 261375      leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 2 130815      leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 2 65535       leaky_re_lu_45[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 62,001,757\n",
      "Trainable params: 61,949,149\n",
      "Non-trainable params: 52,608\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(infer_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model.load_weights(\"./yolo.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
