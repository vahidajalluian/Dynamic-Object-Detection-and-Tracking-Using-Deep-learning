{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import colorsys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from   keras.models               import Sequential, Model ,model_from_yaml ,load_model\n",
    "from   keras.activations          import linear\n",
    "from   keras.layers.normalization import BatchNormalization\n",
    "from   keras.optimizers           import Adagrad\n",
    "from   keras.utils                import plot_model\n",
    "from   keras.engine.topology      import Layer\n",
    "from   yolo3.model                import yolo_eval\n",
    "from   keras                      import backend as K\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# Generate colors for drawing bounding boxes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_class():\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_anchors():\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        anchors = np.array(anchors).reshape(-1, 2)\n",
    "    return anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    assert model_path.endswith('.h5'), 'Keras model must be a .h5 file.'\n",
    "    Infer_model = load_model(model_path)\n",
    "    print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "#     yaml_file = open('infer_model.yaml', 'r')\n",
    "#     loaded_model_yaml = yaml_file.read()\n",
    "#     yaml_file.close()\n",
    "#    Infer_model = model_from_yaml(loaded_model_yaml)\n",
    "    # Generate output tensor targets for filtered bounding boxes.\n",
    "    input_image_shape = K.placeholder(shape=(2, ))\n",
    "    boxes, scores, classes = yolo_eval(Infer_model.output, anchors,\n",
    "                                       len(class_names), input_image_shape,\n",
    "                                       score_threshold=score, iou_threshold=iou)\n",
    "    return Infer_model,boxes, scores, classes,input_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_session(self):\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(image,Infer_model,input_image_shape, animals=1, predictEdge=0, pos=-1, database=None):\n",
    "    predictEdge /= 100\n",
    "    if is_fixed_size:\n",
    "        assert model_image_size[0] % 32 == 0, 'Multiples of 32 required'\n",
    "        assert model_image_size[1] % 32 == 0, 'Multiples of 32 required'\n",
    "        boxed_image = cv2.resize(image,model_image_size)\n",
    "    else:\n",
    "        new_image_size = (image.width - (image.width % 32),\n",
    "                          image.height - (image.height % 32))\n",
    "        boxed_image = letterbox_image(image, new_image_size)\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "    # print(image_data.shape)\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    out_boxes, out_scores, out_classes = sess.run(\n",
    "        [boxes, scores, classes],\n",
    "        feed_dict={\n",
    "            Infer_model.input: image_data,\n",
    "            input_image_shape: [boxed_image.shape[0], boxed_image.shape[1]],\n",
    "            K.learning_phase(): 0\n",
    "        })\n",
    "\n",
    "#    print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "    thickness = (image.shape[0] + image.shape[1]) // 300\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "        score = float(score)\n",
    "        score = round(score, 2)\n",
    "#        print(score, predicted_class, c ,box)\n",
    "#        if((score < predictEdge) or ((animals >> c) & 1 == 0)):\n",
    "#            continue\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "        label_size = 10\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.shape[0], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.shape[1], np.floor(right + 0.5).astype('int32'))\n",
    "        # print(label, (left, top), (right, bottom), pos, c, type(top))\n",
    "        if(pos != -1):\n",
    "            database.insert({\"pos\": pos, \"left\": int(left), \"right\": int(right),\n",
    "                             \"top\": int(top), \"bottom\": int(bottom), \"predict\": int(c), \"score\": score})\n",
    "        if top - label_size >= 0:\n",
    "            text_origin = np.array([left, top - label_size])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "        cv2.rectangle(boxed_image,(left,top),(right,bottom),colors[c],3)    \n",
    "        cv2.putText(boxed_image,label,tuple(text_origin),font,1,colors[c])\n",
    "    # end = time.time()\n",
    "    # print(end - start)\n",
    "    return boxed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path   = 'yolov3_weights.h5'\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "classes_path = 'model_data/coco_classes.txt'\n",
    "score = 0.3\n",
    "iou = 0.5\n",
    "class_names = _get_class()\n",
    "anchors = _get_anchors()\n",
    "sess = K.get_session()\n",
    "hsv_tuples = [(x / len(class_names), 1., 1.)\n",
    "              for x in range(len(class_names))]\n",
    "colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "colors = list(\n",
    "    map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "        colors))\n",
    "random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "# Shuffle colors to decorrelate adjacent classes.\n",
    "random.shuffle(colors)\n",
    "random.seed(None)  # Reset seed to default.\n",
    "model_image_size = (416, 416)  # fixed size or (None, None)\n",
    "is_fixed_size = model_image_size != (None, None)\n",
    "Infer_model,boxes, scores, classes,input_image_shape = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./test2.jpg\",cv2.IMREAD_COLOR)\n",
    "det_image=detect_image(image,Infer_model,input_image_shape)\n",
    "plt.figure(figsize=(416,416))\n",
    "plt.imshow(det_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
