{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model V0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net Data\n",
    "    \n",
    "| batch=1 | subdivisions=1 | Training |\n",
    "| :---: | :---: | :---: |\n",
    "| decay=0.0005 | angle=0 | saturation = 1.5 |\n",
    "| batch=64 | subdivisions=16 | width=608 |\n",
    "| height=608 | channels=3 | momentum=0.9 |\n",
    "|exposure = 1.5 | hue=.1 | learning_rate=0.001|\n",
    "|burn_in=1000| max_batches = 500200| policy=steps|  \n",
    "|steps=400000,450000|scales=.1,.1||\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, Dense, Conv2D, LeakyReLU, ZeroPadding2D , Add , UpSampling2D , concatenate\n",
    "from keras.layers import concatenate\n",
    "from keras.activations import linear\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.utils import plot_model\n",
    "from keras.engine.topology import Layer\n",
    "import tensorflow as tf\n",
    "from Yolo_layer import YoloLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['person'       , 'bicycle'      , 'car'          , 'motorcycle',\n",
    "          'airplane'     , 'bus'          , 'train'        , 'truck', \n",
    "          'boat'         , 'traffic light', 'fire hydrant' ,'stop sign',\n",
    "          'parking meter', 'bench'        , 'bird'         , 'cat', \n",
    "          'dog'          , 'horse'        , 'sheep'        ,'cow' , \n",
    "          'elephant'     , 'bear'         , 'zebra'        ,'giraffe',\n",
    "          'backpack'     , 'umbrella'     , 'handbag'      ,'tie',\n",
    "          'suitcase'     , 'frisbee'      , 'skis'         ,'snowboard',\n",
    "          'sports ball'  , 'kite'         , 'baseball bat' , 'baseball glove',\n",
    "          'skateboard'   , 'surfboard'    , 'tennis racket','bottle',\n",
    "          'wine glass'   , 'cup'          , 'fork'         ,'knife',\n",
    "          'spoon'        , 'bowl'         , 'banana'       ,'apple',\n",
    "          'sandwich'     , 'orange'       , 'broccoli'     ,'carrot',\n",
    "          'hot dog'      , 'pizza'        , 'donut'        ,'cake',\n",
    "          'chair'        , 'couch'        , 'potted plant' ,'bed',\n",
    "          'dining table' , 'toilet'       , 'tv'           ,'laptop', \n",
    "          'mouse'        , 'remote'       , 'keyboard'     ,'cell phone',\n",
    "          'microwave'    , 'oven'         , 'toaster'      ,'sink', \n",
    "          'refrigerator' , 'book'         , 'clock'        , 'vase',\n",
    "          'scissors'     , 'teddy bear'   , 'hair drier'   , 'toothbrush']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "nb_class         = len(labels)\n",
    "\n",
    "anchors          = [10,13,16,30,33,23,30,61,62,45,59,119,116,90,156,198,373,326]\n",
    "\n",
    "noobj_scale      = 1.0\n",
    "obj_scale        = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "class_scale      = 1.0\n",
    "\n",
    "batch_size       = 16\n",
    "warmup_batches   = 0\n",
    "TRUE_BOX_BUFFER  = 50\n",
    "\n",
    "\n",
    "ALPHA = 0.1\n",
    "max_grid = 480\n",
    "max_box_per_image = 20\n",
    "\n",
    "# num=9\n",
    "jitter=.3\n",
    "\n",
    "truth_thresh = 1\n",
    "random=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_h, net_w, 3\n",
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3),name='Main_Input') \n",
    "true_boxes  = Input(shape=(1, 1, 1, max_box_per_image, 4))\n",
    "# grid_h, grid_w, nb_anchor, pc+bx+by+bh+bw+nb_class\n",
    "true_yolo_1 = Input(shape=(None, None, len(anchors)//6, 5+nb_class)) \n",
    "true_yolo_2 = Input(shape=(None, None, len(anchors)//6, 5+nb_class)) \n",
    "true_yolo_3 = Input(shape=(None, None, len(anchors)//6, 5+nb_class)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv\n",
    "# Layer 1\n",
    "\n",
    "lay1_1 = Conv2D(32, 3, strides=(1, 1), padding='same',name='Layer_1_CONV')(input_image)\n",
    "lay1_2 = BatchNormalization(epsilon=0.001,name='Layer_1_Batch')(lay1_1)\n",
    "lay1_3 = LeakyReLU(alpha=ALPHA,name='Layer_1_LRELU')(lay1_2)\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# Conv\n",
    "# Layer 2\n",
    "\n",
    "lay2_1 = ZeroPadding2D(((1,0),(1,0)),name='Layer_2')(lay1_3)\n",
    "lay2_2 = Conv2D(64, 3, strides=(2, 2), padding='valid',name='Layer_2_CONV')(lay2_1)\n",
    "lay2_3 = BatchNormalization(epsilon=0.001)(lay2_2)\n",
    "lay2_4 = LeakyReLU(alpha=ALPHA)(lay2_3)\n",
    "\n",
    "# Conv\n",
    "# Layer 3\n",
    "\n",
    "lay3_1 = Conv2D(32, 1, strides=(1, 1), padding='same',name='Layer_3_CONV')(lay2_4)\n",
    "lay3_2 = BatchNormalization(epsilon=0.001)(lay3_1)\n",
    "lay3_3 = LeakyReLU(alpha=ALPHA)(lay3_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 4\n",
    "\n",
    "lay4_1 = Conv2D(64, 3, strides=(1, 1), padding='same',name='Layer_4_CONV')(lay3_3)\n",
    "lay4_2 = BatchNormalization(epsilon=0.001)(lay4_1)\n",
    "lay4_3 = LeakyReLU(alpha=ALPHA)(lay4_2)\n",
    "\n",
    "# Shortcut\n",
    "# Layer 5\n",
    "\n",
    "lay5_1 = Add()([lay4_3, lay2_4])\n",
    "lay5_2 = linear(lay5_1)\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# Conv\n",
    "# Layer 6\n",
    "\n",
    "lay6_1 = ZeroPadding2D(((1,0),(1,0)))(lay5_2)\n",
    "lay6_2 = Conv2D(128, 3, strides=(2, 2), padding='valid')(lay6_1)\n",
    "lay6_3 = BatchNormalization(epsilon=0.001)(lay6_2)\n",
    "lay6_4 = LeakyReLU(alpha=ALPHA)(lay6_3)\n",
    "\n",
    "# Conv\n",
    "# Layer 7\n",
    "\n",
    "lay7_1 = Conv2D(64, 1, strides=(1, 1), padding='same')(lay6_4)\n",
    "lay7_2 = BatchNormalization(epsilon=0.001)(lay7_1)\n",
    "lay7_3 = LeakyReLU(alpha=ALPHA)(lay7_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 8\n",
    "\n",
    "lay8_1 = Conv2D(128, 3, strides=(1, 1), padding='same')(lay7_3)\n",
    "lay8_2 = BatchNormalization(epsilon=0.001)(lay8_1)\n",
    "lay8_3 = LeakyReLU(alpha=ALPHA)(lay8_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 9\n",
    "\n",
    "lay9_1 = Add()([lay8_3,lay6_3])\n",
    "lay9_2 = linear(lay9_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 10\n",
    "\n",
    "lay10_1 = Conv2D(64, 1, strides=(1, 1), padding='same')(lay9_2)\n",
    "lay10_2 = BatchNormalization(epsilon=0.001)(lay10_1)\n",
    "lay10_3 = LeakyReLU(alpha=ALPHA)(lay10_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 11\n",
    "\n",
    "lay11_1 = Conv2D(128, 3, strides=(1, 1), padding='same')(lay10_3)\n",
    "lay11_2 = BatchNormalization(epsilon=0.001)(lay11_1)\n",
    "lay11_3 = LeakyReLU(alpha=ALPHA)(lay11_2)\n",
    "\n",
    "# Shortcut \n",
    "# layer 12\n",
    "\n",
    "lay12_1 = Add()([lay11_3,lay9_2])\n",
    "lay12_2 = linear(lay12_1)\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# Conv \n",
    "# Layer 13\n",
    "\n",
    "lay13_1 = ZeroPadding2D(((1,0),(1,0)))(lay12_2)\n",
    "lay13_2 = Conv2D(256, 3, strides=(2, 2), padding='valid')(lay13_1)\n",
    "lay13_3 = BatchNormalization(epsilon=0.001)(lay13_2)\n",
    "lay13_4 = LeakyReLU(alpha=ALPHA)(lay13_3)\n",
    "\n",
    "# Conv\n",
    "# Layer 14\n",
    "\n",
    "lay14_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay13_4)\n",
    "lay14_2 = BatchNormalization(epsilon=0.001)(lay14_1)\n",
    "lay14_3 = LeakyReLU(alpha=ALPHA)(lay14_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 15\n",
    "\n",
    "lay15_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay14_3)\n",
    "lay15_2 = BatchNormalization(epsilon=0.001)(lay15_1)\n",
    "lay15_3 = LeakyReLU(alpha=ALPHA)(lay15_2)\n",
    "\n",
    "\n",
    "# Shortcut\n",
    "# Layer 16\n",
    "\n",
    "lay16_1 = Add()([lay15_3,lay13_4])\n",
    "lay16_2 = linear(lay16_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 17\n",
    "\n",
    "lay17_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay16_2)\n",
    "lay17_2 = BatchNormalization(epsilon=0.001)(lay17_1)\n",
    "lay17_3 = LeakyReLU(alpha=ALPHA)(lay17_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 18\n",
    "\n",
    "lay18_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay17_3)\n",
    "lay18_2 = BatchNormalization(epsilon=0.001)(lay18_1)\n",
    "lay18_3 = LeakyReLU(alpha=ALPHA)(lay18_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 19\n",
    "\n",
    "lay19_1 = Add()([lay18_3,lay16_2])\n",
    "lay19_2 = linear(lay19_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 20\n",
    "\n",
    "lay20_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay19_2)\n",
    "lay20_2 = BatchNormalization(epsilon=0.001)(lay20_1)\n",
    "lay20_3 = LeakyReLU(alpha=ALPHA)(lay20_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 21\n",
    "\n",
    "lay21_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay20_3)\n",
    "lay21_2 = BatchNormalization(epsilon=0.001)(lay21_1)\n",
    "lay21_3 = LeakyReLU(alpha=ALPHA)(lay21_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 22\n",
    "\n",
    "lay22_1 = Add ()([lay21_3,lay19_2])\n",
    "lay22_2 = linear(lay22_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 23\n",
    "\n",
    "lay23_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay22_2)\n",
    "lay23_2 = BatchNormalization(epsilon=0.001)(lay23_1)\n",
    "lay23_3 = LeakyReLU(alpha=ALPHA)(lay23_2)\n",
    "\n",
    "# Conv \n",
    "# Layer 24 \n",
    "\n",
    "lay24_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay23_3)\n",
    "lay24_2 = BatchNormalization(epsilon=0.001)(lay24_1)\n",
    "lay24_3 = LeakyReLU(alpha=ALPHA)(lay24_2)\n",
    "\n",
    "\n",
    "# Shortcut \n",
    "# Layer 25\n",
    "\n",
    "lay25_1 = Add()([lay24_3,lay22_2])\n",
    "lay25_2 = linear(lay25_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 26\n",
    "\n",
    "lay26_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay25_2)\n",
    "lay26_2 = BatchNormalization(epsilon=0.001)(lay26_1)\n",
    "lay26_3 = LeakyReLU(alpha=ALPHA)(lay26_2)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 27\n",
    "\n",
    "lay27_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay26_2)\n",
    "lay27_2 = BatchNormalization(epsilon=0.001)(lay27_1)\n",
    "lay27_3 = LeakyReLU(alpha=ALPHA)(lay27_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 28\n",
    "\n",
    "lay28_1 = Add()([lay27_3,lay25_2])\n",
    "lay28_2 = linear(lay28_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 29\n",
    "\n",
    "lay29_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay28_2)\n",
    "lay29_2 = BatchNormalization(epsilon=0.001)(lay29_1)\n",
    "lay29_3 = LeakyReLU(alpha=ALPHA)(lay29_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 30\n",
    "\n",
    "lay30_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay29_3)\n",
    "lay30_2 = BatchNormalization(epsilon=0.001)(lay30_1)\n",
    "lay30_3 = LeakyReLU(alpha=ALPHA)(lay30_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 31\n",
    "\n",
    "\n",
    "lay31_1 = Add()([lay30_3,lay28_2])\n",
    "lay31_2 = linear(lay31_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 32\n",
    "\n",
    "lay32_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay31_2)\n",
    "lay32_2 = BatchNormalization(epsilon=0.001)(lay32_1)\n",
    "lay32_3 = LeakyReLU(alpha=ALPHA)(lay32_2)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 33\n",
    "\n",
    "lay33_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay32_3)\n",
    "lay33_2 = BatchNormalization(epsilon=0.001)(lay33_1)\n",
    "lay33_3 = LeakyReLU(alpha=ALPHA)(lay33_2)\n",
    "\n",
    "# Shortcut\n",
    "# Layer 34\n",
    "\n",
    "lay34_1 = Add()([lay33_3,lay31_2])\n",
    "lay34_2 = linear(lay34_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 35\n",
    "\n",
    "lay35_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay34_2)\n",
    "lay35_2 = BatchNormalization(epsilon=0.001)(lay33_1)\n",
    "lay35_3 = LeakyReLU(alpha=ALPHA)(lay33_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 36\n",
    "\n",
    "lay36_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay35_3)\n",
    "lay36_2 = BatchNormalization(epsilon=0.001)(lay36_1)\n",
    "lay36_3 = LeakyReLU(alpha=ALPHA)(lay36_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 37\n",
    "\n",
    "lay37_1 = Add()([lay36_3,lay34_2])\n",
    "lay37_2 = linear(lay37_1)\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# Conv\n",
    "# Layer 38\n",
    "\n",
    "lay38_1 = ZeroPadding2D(((1,0),(1,0)))(lay37_2)\n",
    "lay38_2 = Conv2D(512, 3, strides=(2, 2), padding='valid')(lay38_1)\n",
    "lay38_3 = BatchNormalization(epsilon=0.001)(lay38_2)\n",
    "lay38_4 = LeakyReLU(alpha=ALPHA)(lay38_3)\n",
    "\n",
    "# Conv\n",
    "# Layer 39\n",
    "\n",
    "lay39_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay38_4)\n",
    "lay39_2 = BatchNormalization(epsilon=0.001)(lay39_1)\n",
    "lay39_3 = LeakyReLU(alpha=ALPHA)(lay39_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 40\n",
    "\n",
    "lay40_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay39_3)\n",
    "lay40_2 = BatchNormalization(epsilon=0.001)(lay40_1)\n",
    "lay40_3 = LeakyReLU(alpha=ALPHA)(lay40_2)\n",
    "\n",
    "\n",
    "# Shortcut\n",
    "# Layer 41\n",
    "\n",
    "lay41_1 = Add()([lay40_3,lay38_4])\n",
    "lay41_2 = linear(lay41_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 42\n",
    "\n",
    "lay42_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay41_2)\n",
    "lay42_2 = BatchNormalization(epsilon=0.001)(lay42_1)\n",
    "lay42_3 = LeakyReLU(alpha=ALPHA)(lay42_2)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 43\n",
    "\n",
    "lay43_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay42_2)\n",
    "lay43_2 = BatchNormalization(epsilon=0.001)(lay43_1)\n",
    "lay43_3 = LeakyReLU(alpha=ALPHA)(lay43_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 44\n",
    "\n",
    "lay44_1 = Add()([lay43_3,lay41_2])\n",
    "lay44_2 = linear(lay44_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 45\n",
    "\n",
    "lay45_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay44_2)\n",
    "lay45_2 = BatchNormalization(epsilon=0.001)(lay45_1)\n",
    "lay45_3 = LeakyReLU(alpha=ALPHA)(lay45_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 46\n",
    "\n",
    "lay46_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay45_3)\n",
    "lay46_2 = BatchNormalization(epsilon=0.001)(lay46_1)\n",
    "lay46_3 = LeakyReLU(alpha=ALPHA)(lay46_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 47\n",
    "\n",
    "lay47_1 = Add()([lay46_3,lay44_2])\n",
    "lay47_2 = linear(lay47_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 48\n",
    "\n",
    "lay48_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay47_2)\n",
    "lay48_2 = BatchNormalization(epsilon=0.001)(lay48_1)\n",
    "lay48_3 = LeakyReLU(alpha=ALPHA)(lay48_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 49\n",
    "\n",
    "lay49_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay48_3)\n",
    "lay49_2 = BatchNormalization(epsilon=0.001)(lay49_1)\n",
    "lay49_3 = LeakyReLU(alpha=ALPHA)(lay49_2)\n",
    "\n",
    "# Shortcut\n",
    "# Layer 50\n",
    "\n",
    "lay50_1 = Add()([lay49_3,lay47_2])\n",
    "lay50_2 = linear(lay50_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 51\n",
    "\n",
    "lay51_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay50_2)\n",
    "lay51_2 = BatchNormalization(epsilon=0.001)(lay51_1)\n",
    "lay51_3 = LeakyReLU(alpha=ALPHA)(lay51_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 52\n",
    "\n",
    "lay52_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay51_3)\n",
    "lay52_2 = BatchNormalization(epsilon=0.001)(lay52_1)\n",
    "lay52_3 = LeakyReLU(alpha=ALPHA)(lay52_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 53\n",
    "\n",
    "lay53_1 = Add()([lay52_3,lay50_2])\n",
    "lay53_2 = linear(lay53_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 54\n",
    "\n",
    "lay54_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay53_2)\n",
    "lay54_2 = BatchNormalization(epsilon=0.001)(lay54_1)\n",
    "lay54_3 = LeakyReLU(alpha=ALPHA)(lay54_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 55\n",
    "\n",
    "lay55_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay54_3)\n",
    "lay55_2 = BatchNormalization(epsilon=0.001)(lay55_1)\n",
    "lay55_3 = LeakyReLU(alpha=ALPHA)(lay55_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 56\n",
    "\n",
    "lay56_1 = Add()([lay55_3,lay53_2])\n",
    "lay56_2 = linear(lay56_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 57\n",
    "\n",
    "lay57_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay56_2)\n",
    "lay57_2 = BatchNormalization(epsilon=0.001)(lay57_1)\n",
    "lay57_3 = LeakyReLU(alpha=ALPHA)(lay57_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 58\n",
    "\n",
    "lay58_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay57_3)\n",
    "lay58_2 = BatchNormalization(epsilon=0.001)(lay58_1)\n",
    "lay58_3 = LeakyReLU(alpha=ALPHA)(lay58_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 59\n",
    "\n",
    "lay59_1 = Add()([lay58_3,lay56_2])\n",
    "lay59_2 = linear(lay59_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 60\n",
    "\n",
    "lay60_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay59_2)\n",
    "lay60_2 = BatchNormalization(epsilon=0.001)(lay60_1)\n",
    "lay60_3 = LeakyReLU(alpha=ALPHA)(lay60_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 61\n",
    "\n",
    "lay61_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay60_3)\n",
    "lay61_2 = BatchNormalization(epsilon=0.001)(lay61_1)\n",
    "lay61_3 = LeakyReLU(alpha=ALPHA)(lay61_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 62\n",
    "\n",
    "lay62_1 = Add()([lay61_3,lay59_2])\n",
    "lay62_2 = linear(lay62_1)\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# Conv\n",
    "# Layer 63\n",
    "\n",
    "lay63_1 = ZeroPadding2D(((1,0),(1,0)))(lay62_2)\n",
    "lay63_2 = Conv2D(1024, 3, strides=(2, 2), padding='valid')(lay63_1)\n",
    "lay63_3 = BatchNormalization(epsilon=0.001)(lay63_2)\n",
    "lay63_4 = LeakyReLU(alpha=ALPHA)(lay63_3)\n",
    "\n",
    "# Conv\n",
    "# Layer 64\n",
    "\n",
    "lay64_1 = Conv2D(512, 1, strides=(1, 1), padding='same')(lay63_4)\n",
    "lay64_2 = BatchNormalization(epsilon=0.001)(lay64_1)\n",
    "lay64_3 = LeakyReLU(alpha=ALPHA)(lay64_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 65\n",
    "\n",
    "lay65_1 = Conv2D(1024, 3, strides=(1, 1), padding='same')(lay64_3)\n",
    "lay65_2 = BatchNormalization(epsilon=0.001)(lay65_1)\n",
    "lay65_3 = LeakyReLU(alpha=ALPHA)(lay65_2)\n",
    "\n",
    "# Shortcut\n",
    "# Layer 66\n",
    "\n",
    "lay66_1 = Add()([lay65_3,lay63_4])\n",
    "lay66_2 = linear(lay66_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 67\n",
    "\n",
    "lay67_1 = Conv2D(512, 1, strides=(1, 1), padding='same')(lay66_2)\n",
    "lay67_2 = BatchNormalization(epsilon=0.001)(lay67_1)\n",
    "lay67_3 = LeakyReLU(alpha=ALPHA)(lay67_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 68\n",
    "\n",
    "lay68_1 = Conv2D(1024, 3, strides=(1, 1), padding='same')(lay67_3)\n",
    "lay68_2 = BatchNormalization(epsilon=0.001)(lay65_1)\n",
    "lay68_3 = LeakyReLU(alpha=ALPHA)(lay65_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 69\n",
    "\n",
    "lay69_1 = Add()([lay68_3,lay66_2])\n",
    "lay69_2 = linear(lay69_1)\n",
    "\n",
    "# Conv\n",
    "# Layer 70\n",
    "\n",
    "lay70_1 = Conv2D(512, 1, strides=(1, 1), padding='same')(lay69_2)\n",
    "lay70_2 = BatchNormalization(epsilon=0.001)(lay70_1)\n",
    "lay70_3 = LeakyReLU(alpha=ALPHA)(lay70_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 71\n",
    "\n",
    "lay71_1 = Conv2D(1024, 3, strides=(1, 1), padding='same')(lay70_3)\n",
    "lay71_2 = BatchNormalization(epsilon=0.001)(lay71_1)\n",
    "lay71_3 = LeakyReLU(alpha=ALPHA)(lay71_2)\n",
    "\n",
    "# Shortcut\n",
    "# Layer 72\n",
    "\n",
    "lay72_1 = Add()([lay71_3,lay69_2])\n",
    "lay72_2 = linear(lay72_1)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 73\n",
    "\n",
    "lay73_1 = Conv2D(512, 1, strides=(1, 1), padding='same')(lay72_2)\n",
    "lay73_2 = BatchNormalization(epsilon=0.001)(lay73_1)\n",
    "lay73_3 = LeakyReLU(alpha=ALPHA)(lay73_2)\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 74\n",
    "\n",
    "lay74_1 = Conv2D(1024, 3, strides=(1, 1), padding='same')(lay73_3)\n",
    "lay74_2 = BatchNormalization(epsilon=0.001)(lay74_1)\n",
    "lay74_3 = LeakyReLU(alpha=ALPHA)(lay74_2)\n",
    "\n",
    "# Shortcut \n",
    "# Layer 75\n",
    "\n",
    "lay75_1 = Add()([lay74_3,lay72_2])\n",
    "lay75_2 = linear(lay75_1)\n",
    "\n",
    "# ######################\n",
    "\n",
    "# Conv\n",
    "# Layer 76\n",
    "\n",
    "lay76_1 = Conv2D(512, 1, strides=(1, 1), padding='same')(lay75_2)\n",
    "lay76_2 = BatchNormalization(epsilon=0.001)(lay76_1)\n",
    "lay76_3 = LeakyReLU(alpha=ALPHA)(lay76_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 77\n",
    "\n",
    "lay77_1 = Conv2D(1024, 3, strides=(1, 1), padding='same')(lay76_3)\n",
    "lay77_2 = BatchNormalization(epsilon=0.001)(lay77_1)\n",
    "lay77_3 = LeakyReLU(alpha=ALPHA)(lay77_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 78\n",
    "\n",
    "lay78_1 = Conv2D(512, 1, strides=(1, 1), padding='same')(lay77_3)\n",
    "lay78_2 = BatchNormalization(epsilon=0.001)(lay78_1)\n",
    "lay78_3 = LeakyReLU(alpha=ALPHA)(lay78_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 79\n",
    "\n",
    "lay79_1 = Conv2D(1024, 3, strides=(1, 1), padding='same')(lay78_3)\n",
    "lay79_2 = BatchNormalization(epsilon=0.001)(lay79_1)\n",
    "lay79_3 = LeakyReLU(alpha=ALPHA)(lay79_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 80\n",
    "\n",
    "lay80_1 = Conv2D(512, 1, strides=(1, 1), padding='same')(lay79_3)\n",
    "lay80_2 = BatchNormalization(epsilon=0.001)(lay80_1)\n",
    "lay80_3 = LeakyReLU(alpha=ALPHA)(lay80_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 81\n",
    "\n",
    "lay81_1 = Conv2D(1024, 3, strides=(1, 1), padding='same')(lay80_3)\n",
    "lay81_2 = BatchNormalization(epsilon=0.001)(lay81_1)\n",
    "lay81_3 = LeakyReLU(alpha=ALPHA)(lay81_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 82\n",
    "\n",
    "lay82_1 = Conv2D(255, 1, strides=(1, 1), padding='same')(lay81_3)\n",
    "lay82_2 = BatchNormalization(epsilon=0.001)(lay82_1)\n",
    "lay82_3 = LeakyReLU(alpha=ALPHA)(lay82_2)\n",
    "\n",
    "# [yolo] \n",
    "# Prediction Layer in First Scale\n",
    "\n",
    "# mask = 6,7,8\n",
    "# pred_yolo_1 = Conv2D((3*(5+nb_class)), 1, strides=(1, 1), padding='same')(lay82_3)\n",
    "# ignore_thresh = .7\n",
    "\n",
    "# Loss Layer in First Scale\n",
    "# loss_yolo_1 = YoloLayer(anchors[12:], \n",
    "#                         [1*num for num in max_grid], \n",
    "#                         batch_size, \n",
    "#                         warmup_batches, \n",
    "#                         ignore_thresh, \n",
    "#                         grid_scales[0],\n",
    "#                         obj_scale,\n",
    "#                         noobj_scale,\n",
    "#                         xywh_scale,\n",
    "#                         class_scale)([input_image, pred_yolo_1, \n",
    "#                                       true_yolo_1, true_boxes])\n",
    "\n",
    "\n",
    "# Conv\n",
    "# Layer 83\n",
    "\n",
    "lay83_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay82_3)\n",
    "lay83_2 = BatchNormalization(epsilon=0.001)(lay83_1)\n",
    "lay83_3 = LeakyReLU(alpha=ALPHA)(lay83_2)\n",
    "\n",
    "# [upsample] 84\n",
    "# stride=2\n",
    "\n",
    "lay84_1 = UpSampling2D(2)(lay83_3)\n",
    "\n",
    "# [route] 85 Concatenante\n",
    "# layers = -1, 61\n",
    "\n",
    "lay85_1 = concatenate([lay84_1,lay62_2],axis=-1)\n",
    "\n",
    "# Conv\n",
    "# Layer 86\n",
    "\n",
    "lay86_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay85_1)\n",
    "lay86_2 = BatchNormalization(epsilon=0.001)(lay86_1)\n",
    "lay86_3 = LeakyReLU(alpha=ALPHA)(lay86_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 87\n",
    "\n",
    "lay87_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay86_3)\n",
    "lay87_2 = BatchNormalization(epsilon=0.001)(lay86_1)\n",
    "lay87_3 = LeakyReLU(alpha=ALPHA)(lay86_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 88\n",
    "\n",
    "lay88_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay87_3)\n",
    "lay88_2 = BatchNormalization(epsilon=0.001)(lay88_1)\n",
    "lay88_3 = LeakyReLU(alpha=ALPHA)(lay88_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 89\n",
    "\n",
    "lay89_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay88_3)\n",
    "lay89_2 = BatchNormalization(epsilon=0.001)(lay89_1)\n",
    "lay89_3 = LeakyReLU(alpha=ALPHA)(lay89_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 90\n",
    "\n",
    "lay90_1 = Conv2D(256, 1, strides=(1, 1), padding='same')(lay89_3)\n",
    "lay90_2 = BatchNormalization(epsilon=0.001)(lay90_1)\n",
    "lay90_3 = LeakyReLU(alpha=ALPHA)(lay90_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 91\n",
    "\n",
    "lay91_1 = Conv2D(512, 3, strides=(1, 1), padding='same')(lay90_3)\n",
    "lay91_2 = BatchNormalization(epsilon=0.001)(lay91_1)\n",
    "lay91_3 = LeakyReLU(alpha=ALPHA)(lay91_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 92\n",
    "\n",
    "lay92_1 = Conv2D(255, 1, strides=(1, 1), padding='same')(lay91_3)\n",
    "lay92_2 = BatchNormalization(epsilon=0.001)(lay92_1)\n",
    "lay92_3 = LeakyReLU(alpha=ALPHA)(lay92_2)\n",
    "\n",
    "\n",
    "# [yolo] \n",
    "# mask = 3,4,5\n",
    "# anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
    "# classes=80\n",
    "# num=9\n",
    "# jitter=.3\n",
    "# ignore_thresh = .7\n",
    "# truth_thresh = 1\n",
    "# random=1\n",
    "\n",
    "# Conv\n",
    "# Layer 93\n",
    "\n",
    "lay93_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay92_3)\n",
    "lay93_2 = BatchNormalization(epsilon=0.001)(lay93_1)\n",
    "lay93_3 = LeakyReLU(alpha=ALPHA)(lay93_2)\n",
    "\n",
    "# Upsample\n",
    "# Layer 94\n",
    "# stride=2\n",
    "\n",
    "lay94_1 = UpSampling2D(2)(lay93_3)\n",
    "\n",
    "# [route] 95\n",
    "# layers = -1, 36\n",
    "\n",
    "lay95_1 = concatenate([lay94_1,lay37_2],axis=-1)\n",
    "\n",
    "# Conv \n",
    "# Layer 96 \n",
    "\n",
    "lay96_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay95_1)\n",
    "lay96_2 = BatchNormalization(epsilon=0.001)(lay96_1)\n",
    "lay96_3 = LeakyReLU(alpha=ALPHA)(lay96_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 97\n",
    "\n",
    "lay97_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay96_3)\n",
    "lay97_2 = BatchNormalization(epsilon=0.001)(lay97_1)\n",
    "lay97_3 = LeakyReLU(alpha=ALPHA)(lay97_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 98\n",
    "\n",
    "lay98_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay97_3)\n",
    "lay98_2 = BatchNormalization(epsilon=0.001)(lay98_1)\n",
    "lay98_3 = LeakyReLU(alpha=ALPHA)(lay98_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 99\n",
    "\n",
    "lay99_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay98_3)\n",
    "lay99_2 = BatchNormalization(epsilon=0.001)(lay99_1)\n",
    "lay99_3 = LeakyReLU(alpha=ALPHA)(lay99_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 100\n",
    "\n",
    "lay100_1 = Conv2D(128, 1, strides=(1, 1), padding='same')(lay99_3)\n",
    "lay100_2 = BatchNormalization(epsilon=0.001)(lay100_1)\n",
    "lay100_3 = LeakyReLU(alpha=ALPHA)(lay100_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 101\n",
    "\n",
    "lay101_1 = Conv2D(256, 3, strides=(1, 1), padding='same')(lay100_3)\n",
    "lay101_2 = BatchNormalization(epsilon=0.001)(lay101_1)\n",
    "lay101_3 = LeakyReLU(alpha=ALPHA)(lay101_2)\n",
    "\n",
    "# Conv\n",
    "# Layer 102\n",
    "\n",
    "lay102_1 = Conv2D(255, 1, strides=(1, 1), padding='same')(lay101_3)\n",
    "lay102_2 = BatchNormalization(epsilon=0.001)(lay102_1)\n",
    "lay102_3 = LeakyReLU(alpha=ALPHA)(lay102_2)\n",
    "\n",
    "\n",
    "# [yolo] \n",
    "# mask = 0,1,2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_image, outputs=lay102_3)\n",
    "plot_model(model, to_file='model.png',show_shapes='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Main_Input (InputLayer)         (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Layer_1_CONV (Conv2D)           (None, 416, 416, 32) 896         Main_Input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Layer_1_Batch (BatchNormalizati (None, 416, 416, 32) 128         Layer_1_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer_1_LRELU (LeakyReLU)       (None, 416, 416, 32) 0           Layer_1_Batch[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_2 (ZeroPadding2D)         (None, 417, 417, 32) 0           Layer_1_LRELU[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer_2_CONV (Conv2D)           (None, 208, 208, 64) 18496       Layer_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 208, 208, 64) 256         Layer_2_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 208, 208, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_3_CONV (Conv2D)           (None, 208, 208, 32) 2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 208, 208, 32) 128         Layer_3_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 208, 208, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Layer_4_CONV (Conv2D)           (None, 208, 208, 64) 18496       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 208, 208, 64) 256         Layer_4_CONV[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 208, 208, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 208, 208, 64) 0           leaky_re_lu_3[0][0]              \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 209, 209, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 104, 104, 128 73856       zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 104, 104, 128 512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 104, 104, 64) 8256        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 104, 104, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 104, 104, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 104, 104, 128 73856       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 104, 104, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 104, 104, 128 0           leaky_re_lu_6[0][0]              \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 104, 104, 64) 8256        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 104, 104, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 104, 104, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 104, 104, 128 73856       leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 104, 104, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 104, 104, 128 0           leaky_re_lu_8[0][0]              \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 105, 105, 128 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 52, 52, 256)  295168      zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 52, 52, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 52, 52, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 52, 52, 128)  32896       leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 52, 52, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 52, 52, 256)  295168      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 52, 52, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 52, 52, 256)  0           leaky_re_lu_11[0][0]             \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 52, 52, 128)  32896       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 52, 52, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 52, 52, 256)  295168      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 52, 52, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 52, 52, 256)  0           leaky_re_lu_13[0][0]             \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 52, 52, 128)  32896       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 52, 52, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 52, 52, 256)  295168      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 52, 52, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 52, 52, 256)  0           leaky_re_lu_15[0][0]             \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 52, 52, 128)  32896       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 52, 52, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 52, 52, 256)  295168      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 52, 52, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 52, 52, 256)  0           leaky_re_lu_17[0][0]             \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 52, 52, 128)  32896       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 52, 52, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 52, 52, 256)  295168      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 52, 52, 256)  1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 52, 52, 256)  0           leaky_re_lu_19[0][0]             \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 52, 52, 128)  32896       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 52, 52, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 52, 52, 256)  295168      leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 52, 52, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 52, 52, 256)  0           leaky_re_lu_21[0][0]             \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 52, 52, 128)  32896       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 52, 52, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 52, 52, 256)  295168      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 52, 52, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 52, 52, 256)  590080      leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 52, 52, 256)  1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 52, 52, 256)  0           leaky_re_lu_23[0][0]             \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 52, 52, 256)  0           leaky_re_lu_25[0][0]             \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 53, 53, 256)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 26, 26, 512)  1180160     zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 26, 26, 512)  2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 26, 26, 256)  131328      leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 26, 26, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 26, 26, 512)  1180160     leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 26, 26, 512)  2048        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 26, 26, 512)  0           leaky_re_lu_28[0][0]             \n",
      "                                                                 leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 26, 26, 256)  131328      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 26, 26, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 26, 26, 512)  1180160     batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 26, 26, 512)  2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 26, 26, 512)  0           leaky_re_lu_30[0][0]             \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 26, 26, 256)  131328      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 26, 26, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 26, 26, 512)  1180160     leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 26, 26, 512)  2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 26, 26, 512)  0           leaky_re_lu_32[0][0]             \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 26, 26, 256)  131328      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 26, 26, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 26, 26, 512)  1180160     leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 26, 26, 512)  2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 26, 26, 512)  0           leaky_re_lu_34[0][0]             \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 26, 26, 256)  131328      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 26, 26, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 26, 26, 512)  1180160     leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 26, 26, 512)  2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 26, 26, 512)  0           leaky_re_lu_36[0][0]             \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 26, 26, 256)  131328      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 26, 26, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 26, 26, 512)  1180160     leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 26, 26, 512)  2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 26, 26, 512)  0           leaky_re_lu_38[0][0]             \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 26, 26, 256)  131328      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 26, 26, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 26, 26, 512)  1180160     leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 26, 26, 512)  2048        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 26, 26, 512)  0           leaky_re_lu_40[0][0]             \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 26, 26, 256)  131328      add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 26, 26, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 26, 26, 512)  1180160     leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 26, 26, 512)  2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 26, 26, 512)  0           leaky_re_lu_42[0][0]             \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 27, 27, 512)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 13, 13, 1024) 4719616     zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 13, 13, 1024) 4096        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 13, 13, 512)  524800      leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 13, 13, 512)  2048        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 13, 13, 1024) 4719616     leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 13, 13, 1024) 4096        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 13, 13, 1024) 0           leaky_re_lu_45[0][0]             \n",
      "                                                                 leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 13, 13, 1024) 0           leaky_re_lu_47[0][0]             \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 13, 13, 512)  524800      add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 13, 13, 512)  2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 13, 13, 1024) 4719616     leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 13, 13, 1024) 4096        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 13, 13, 1024) 0           leaky_re_lu_49[0][0]             \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 13, 13, 512)  524800      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 13, 13, 512)  2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 13, 13, 1024) 4719616     leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 13, 13, 1024) 4096        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 13, 13, 1024) 0           leaky_re_lu_51[0][0]             \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 13, 13, 512)  524800      add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 13, 13, 512)  2048        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 13, 13, 1024) 4719616     leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 13, 13, 1024) 4096        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 13, 13, 512)  524800      leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 13, 13, 512)  2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 13, 13, 1024) 4719616     leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 13, 13, 1024) 4096        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 13, 13, 512)  524800      leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 13, 13, 512)  2048        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 13, 13, 1024) 4719616     leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 13, 13, 1024) 4096        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 13, 13, 255)  261375      leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 13, 13, 255)  1020        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, 13, 13, 255)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 13, 13, 256)  65536       leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 13, 13, 256)  1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, 13, 13, 256)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 26, 26, 256)  0           leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 26, 26, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 26, 26, 256)  196864      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 26, 26, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 26, 26, 256)  65792       leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 26, 26, 256)  1024        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 26, 26, 512)  1180160     leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 26, 26, 512)  2048        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 26, 26, 256)  131328      leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 26, 26, 256)  1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 26, 26, 512)  1180160     leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 26, 26, 512)  2048        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 26, 26, 255)  130815      leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 26, 26, 255)  1020        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, 26, 26, 255)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 26, 26, 128)  32768       leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 26, 26, 128)  512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, 26, 26, 128)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 52, 52, 128)  0           leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 52, 52, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 52, 52, 128)  49280       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 52, 52, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 52, 52, 256)  295168      leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 52, 52, 256)  1024        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 52, 52, 128)  32896       leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 52, 52, 128)  512         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 52, 52, 256)  295168      leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 52, 52, 256)  1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 52, 52, 128)  32896       leaky_re_lu_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 52, 52, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 52, 52, 256)  295168      leaky_re_lu_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 52, 52, 256)  1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 52, 52, 255)  65535       leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 52, 52, 255)  1020        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)      (None, 52, 52, 255)  0           batch_normalization_74[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 55,728,401\n",
      "Trainable params: 55,678,615\n",
      "Non-trainable params: 49,786\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
